{
    "name": "security",
    "description": "Controls that are used to assess security threats.",
    "attributes": {
        "armoBuiltin": true
    },
    "typeTags": [
        "security"
    ],
    "version": null,
    "controls": [
        {
            "name": "Resource limits",
            "attributes": {
                "armoBuiltin": true,
                "controlTypeTags": [
                    "security"
                ],
                "attackTracks": [
                    {
                        "attackTrack": "container",
                        "categories": [
                            "Impact - service destruction"
                        ]
                    }
                ]
            },
            "description": "CPU and memory resources should have a limit set for every container or a namespace to prevent resource exhaustion. This control identifies all the Pods without resource limit definitions by checking their yaml definition file as well as their namespace LimitRange objects. It is also recommended to use ResourceQuota object to restrict overall namespace resources, but this is not verified by this control.",
            "remediation": "Define LimitRange and Resource Limits in the namespace or in the deployment/POD yamls.",
            "long_description": "CPU and memory resources should have a limit set for every container or a namespace to prevent resource exhaustion. This control identifies all the Pods without resource limit definitions by checking their yaml definition file as well as their namespace LimitRange objects. It is also recommended to use ResourceQuota object to restrict overall namespace resources, but this is not verified by this control.",
            "test": " Check for each container if there is a \u2018limits\u2019 field defined for both cpu and memory",
            "controlID": "C-0009",
            "baseScore": 7.0,
            "example": "@controls/examples/c009.yaml",
            "scanningScope": {
                "matches": [
                    "cluster",
                    "file"
                ]
            },
            "rules": [
                {
                    "name": "resource-policies",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                ""
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Pod"
                            ]
                        },
                        {
                            "apiGroups": [
                                "apps"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet"
                            ]
                        },
                        {
                            "apiGroups": [
                                "batch"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Job",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "fails if namespace has no resource policies defined",
                    "remediation": "Make sure that you definy resource policies (LimitRange or ResourceQuota) which limit the usage of resources for all the namespaces",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\n\n# Check if container has limits\ndeny[msga] {\n  \tpods := [pod | pod = input[_]; pod.kind == \"Pod\"]\n    pod := pods[_]\n\tcontainer := pod.spec.containers[i]\n\t\n\t\n\tbeggining_of_path := \"spec.\"\n\tfixPath := is_no_cpu_and_memory_limits_defined(container, beggining_of_path, i)\n\t\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"there are no cpu and memory  limits defined for container : %v\",  [container.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"fixPaths\": fixPath,\n\t\t\"failedPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}\n\n\n# Check if container has limits - for workloads\n# If there is no limits specified in the workload, we check the namespace, since if limits are only specified for namespace\n# and not in workload, it won't be on the yaml\ndeny[msga] {\n\twl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n\tcontainer := wl.spec.template.spec.containers[i]\n\t\n\tbeggining_of_path\t:= \"spec.template.spec.\"\n\tfixPath := is_no_cpu_and_memory_limits_defined(container, beggining_of_path, i)\n\t\n\t\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"there are no cpu and memory limits defined for container : %v\",  [container.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"fixPaths\": fixPath,\n\t\t\"failedPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n\t\n}\n\n# Check if container has limits - for cronjobs\n# If there is no limits specified in the cronjob, we check the namespace, since if limits are only specified for namespace\n# and not in cronjob, it won't be on the yaml\ndeny [msga] {\n    wl := input[_]\n\twl.kind == \"CronJob\"\n\tcontainer := wl.spec.jobTemplate.spec.template.spec.containers[i]\n\t\n\tbeggining_of_path := \"spec.jobTemplate.spec.template.spec.\"\n\tfixPath := is_no_cpu_and_memory_limits_defined(container, beggining_of_path, i)\n\t\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"there are no cpu and memory limits defined for container : %v\",  [container.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"fixPaths\": fixPath,\n\t\t\"failedPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n# no limits at all\nis_no_cpu_and_memory_limits_defined(container, beggining_of_path, i) =  fixPath {\n\tnot container.resources.limits\n\tfixPath = [{\"path\": sprintf(\"%vcontainers[%v].resources.limits.cpu\", [beggining_of_path, format_int(i, 10)]), \"value\":\"YOUR_VALUE\"}, {\"path\": sprintf(\"%vcontainers[%v].resources.limits.memory\", [beggining_of_path, format_int(i, 10)]), \"value\":\"YOUR_VALUE\"}]\n}\n\n# only memory limit\nis_no_cpu_and_memory_limits_defined(container, beggining_of_path, i) = fixPath {\n\tcontainer.resources.limits\n\tnot container.resources.limits.cpu\n\tcontainer.resources.limits.memory\n\tfixPath = [{\"path\": sprintf(\"%vcontainers[%v].resources.limits.cpu\", [beggining_of_path, format_int(i, 10)]), \"value\":\"YOUR_VALUE\"}]\n}\n\n# only cpu limit\nis_no_cpu_and_memory_limits_defined(container, beggining_of_path, i) =fixPath {\n\tcontainer.resources.limits\n\tnot container.resources.limits.memory\n\tcontainer.resources.limits.cpu\n\tfixPath = [{\"path\": sprintf(\"%vcontainers[%v].resources.limits.memory\", [beggining_of_path, format_int(i, 10)]), \"value\":\"YOUR_VALUE\"}]\n\tfailed_path = \"\"\n}\n# limits but without capu and memory \nis_no_cpu_and_memory_limits_defined(container, beggining_of_path, i) = fixPath {\n\tcontainer.resources.limits\n\tnot container.resources.limits.memory\n\tnot container.resources.limits.cpu\n\tfixPath = [{\"path\": sprintf(\"%vcontainers[%v].resources.limits.cpu\", [beggining_of_path, format_int(i, 10)]), \"value\":\"YOUR_VALUE\"}, {\"path\": sprintf(\"%vcontainers[%v].resources.limits.memory\", [beggining_of_path, format_int(i, 10)]), \"value\":\"YOUR_VALUE\"}]\n}"
                }
            ]
        },
        {
            "name": "Immutable container filesystem",
            "attributes": {
                "armoBuiltin": true,
                "controlTypeTags": [
                    "security",
                    "compliance"
                ],
                "attackTracks": [
                    {
                        "attackTrack": "container",
                        "categories": [
                            "Execution",
                            "Persistence"
                        ]
                    }
                ]
            },
            "description": "Mutable container filesystem can be abused to inject malicious code or data into containers. Use immutable (read-only) filesystem to limit potential attacks.",
            "remediation": "Set the filesystem of the container to read-only when possible (POD securityContext, readOnlyRootFilesystem: true). If containers application needs to write into the filesystem, it is recommended to mount secondary filesystems for specific directories where application require write access.",
            "long_description": "By default, containers are permitted mostly unrestricted execution within their own context. An attacker who has access to a container, can create files and download scripts as he wishes, and modify the underlying application running on the container. ",
            "test": "Check whether the readOnlyRootFilesystem field in the SecurityContext is set to true. ",
            "controlID": "C-0017",
            "baseScore": 3.0,
            "example": "@controls/examples/c017.yaml",
            "scanningScope": {
                "matches": [
                    "cluster",
                    "file"
                ]
            },
            "rules": [
                {
                    "name": "immutable-container-filesystem",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                ""
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Pod"
                            ]
                        },
                        {
                            "apiGroups": [
                                "apps"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet"
                            ]
                        },
                        {
                            "apiGroups": [
                                "batch"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Job",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "fails if container has mutable filesystem",
                    "remediation": "Make sure that the securityContext.readOnlyRootFilesystem field in the container/pod spec is set to true",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\n\n# Fails if pods has container with mutable filesystem\ndeny[msga] {\n    pod := input[_]\n    pod.kind == \"Pod\"\n\tcontainer := pod.spec.containers[i]\n\tbeggining_of_path := \"spec.\"\n    result := is_mutable_filesystem(container, beggining_of_path, i)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"container: %v in pod: %v  has  mutable filesystem\", [container.name, pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": failed_path,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}\n\n# Fails if workload has  container with mutable filesystem \ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n    container := wl.spec.template.spec.containers[i]\n\tbeggining_of_path := \"spec.template.spec.\"\n    result := is_mutable_filesystem(container, beggining_of_path, i)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"container :%v in %v: %v has  mutable filesystem\", [container.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": failed_path,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n\n# Fails if cronjob has  container with mutable filesystem \ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n\tcontainer = wl.spec.jobTemplate.spec.template.spec.containers[i]\n\tbeggining_of_path := \"spec.jobTemplate.spec.template.spec.\"\n\tresult := is_mutable_filesystem(container, beggining_of_path, i)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"container :%v in %v: %v has mutable filesystem\", [container.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": failed_path,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n# Default of readOnlyRootFilesystem is false. This field is only in container spec and not pod spec\nis_mutable_filesystem(container, beggining_of_path, i) = [failed_path, fixPath]  {\n\tcontainer.securityContext.readOnlyRootFilesystem == false\n\tfailed_path = sprintf(\"%vcontainers[%v].securityContext.readOnlyRootFilesystem\", [beggining_of_path, format_int(i, 10)])\n\tfixPath = \"\"\n }\n\n is_mutable_filesystem(container, beggining_of_path, i)  = [failed_path, fixPath] {\n\tnot container.securityContext.readOnlyRootFilesystem == false\n    not container.securityContext.readOnlyRootFilesystem == true\n\tfixPath = {\"path\": sprintf(\"%vcontainers[%v].securityContext.readOnlyRootFilesystem\", [beggining_of_path, format_int(i, 10)]), \"value\": \"true\"}\n\tfailed_path = \"\"\n }\n\n\n get_failed_path(paths) = [paths[0]] {\n\tpaths[0] != \"\"\n} else = []\n\n\nget_fixed_path(paths) = [paths[1]] {\n\tpaths[1] != \"\"\n} else = []\n"
                }
            ]
        },
        {
            "name": "Exposure to Internet",
            "attributes": {
                "armoBuiltin": true,
                "controlTypeTags": [
                    "security"
                ],
                "attackTracks": [
                    {
                        "attackTrack": "workload-external-track",
                        "categories": [
                            "Workload Exposure"
                        ]
                    },
                    {
                        "attackTrack": "",
                        "categories": [
                            ""
                        ]
                    }
                ]
            },
            "description": "This control detect workloads that are exposed on Internet through a Service (NodePort or LoadBalancer) or Ingress. It fails in case it find workloads connected with these resources.",
            "remediation": "The user can evaluate its exposed resources and apply relevant changes wherever needed.",
            "test": "Checks if workloads are exposed through the use of NodePort, LoadBalancer or Ingress",
            "controlID": "C-0256",
            "baseScore": 7.0,
            "scanningScope": {
                "matches": [
                    "cluster",
                    "file"
                ]
            },
            "rules": [
                {
                    "name": "exposure-to-internet",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                ""
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Pod",
                                "Service"
                            ]
                        },
                        {
                            "apiGroups": [
                                "apps"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet"
                            ]
                        },
                        {
                            "apiGroups": [
                                "batch"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Job",
                                "CronJob"
                            ]
                        },
                        {
                            "apiGroups": [
                                "extensions",
                                "networking.k8s.io"
                            ],
                            "apiVersions": [
                                "v1beta1",
                                "v1"
                            ],
                            "resources": [
                                "Ingress"
                            ]
                        }
                    ],
                    "description": "fails in case the running workload has binded Service or Ingress that are exposing it on Internet.",
                    "remediation": "",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\n# Checks if NodePort or LoadBalancer is connected to a workload to expose something\ndeny[msga] {\n    service := input[_]\n    service.kind == \"Service\"\n    is_exposed_service(service)\n    \n    wl := input[_]\n    spec_template_spec_patterns := {\"Deployment\", \"ReplicaSet\", \"DaemonSet\", \"StatefulSet\", \"Pod\", \"Job\", \"CronJob\"}\n    spec_template_spec_patterns[wl.kind]\n    wl_connected_to_service(wl, service)\n    failPath := [\"spec.type\"]\n    msga := {\n        \"alertMessage\": sprintf(\"workload '%v' is exposed through service '%v'\", [wl.metadata.name, service.metadata.name]),\n        \"packagename\": \"armo_builtins\",\n        \"alertScore\": 7,\n        \"fixPaths\": [],\n        \"failedPaths\": [],\n        \"alertObject\": {\n            \"k8sApiObjects\": [wl]\n        },\n        \"relatedObjects\": [{\n            \"object\": service,\n            \"failedPaths\": failPath,\n        }]\n    }\n}\n\n# Checks if Ingress is connected to a service and a workload to expose something\ndeny[msga] {\n    ingress := input[_]\n    ingress.kind == \"Ingress\"\n    \n    svc := input[_]\n    svc.kind == \"Service\"\n    # avoid duplicate alerts\n    # if service is already exposed through NodePort or LoadBalancer workload will fail on that\n    not is_exposed_service(svc)\n\n    wl := input[_]\n    spec_template_spec_patterns := {\"Deployment\", \"ReplicaSet\", \"DaemonSet\", \"StatefulSet\", \"Pod\", \"Job\", \"CronJob\"}\n    spec_template_spec_patterns[wl.kind]\n    wl_connected_to_service(wl, svc)\n\n    result := svc_connected_to_ingress(svc, ingress)\n    \n    msga := {\n        \"alertMessage\": sprintf(\"workload '%v' is exposed through ingress '%v'\", [wl.metadata.name, ingress.metadata.name]),\n        \"packagename\": \"armo_builtins\",\n        \"failedPaths\": [],\n        \"fixPaths\": [],\n        \"alertScore\": 7,\n        \"alertObject\": {\n            \"k8sApiObjects\": [wl]\n        },\n        \"relatedObjects\": [{\n            \"object\": ingress,\n            \"failedPaths\": result,\n        }]\n    }\n} \n\n# ====================================================================================\n\nis_exposed_service(svc) {\n    svc.spec.type == \"NodePort\"\n}\n\nis_exposed_service(svc) {\n    svc.spec.type == \"LoadBalancer\"\n}\n\nwl_connected_to_service(wl, svc) {\n    count({x | svc.spec.selector[x] == wl.metadata.labels[x]}) == count(svc.spec.selector)\n}\n\nwl_connected_to_service(wl, svc) {\n    wl.spec.selector.matchLabels == svc.spec.selector\n}\n\n# check if service is connected to ingress\nsvc_connected_to_ingress(svc, ingress) = result {\n    rule := ingress.spec.rules[i]\n    paths := rule.http.paths[j]\n    svc.metadata.name == paths.backend.service.name\n    result := [sprintf(\"ingress.spec.rules[%d].http.paths[%d].backend.service.name\", [i,j])]\n}\n\n"
                }
            ]
        },
        {
            "name": "Workload with credential access",
            "attributes": {
                "armoBuiltin": true,
                "controlTypeTags": [
                    "security"
                ],
                "attackTracks": [
                    {
                        "attackTrack": "workload-external-track",
                        "categories": [
                            "Credential access"
                        ]
                    }
                ]
            },
            "description": "This control checks if workloads specifications have sensitive information in their environment variables.",
            "remediation": "Use Kubernetes secrets or Key Management Systems to store credentials.",
            "test": "Check if the workload has sensitive information in environment variables, by using list of known sensitive key names.",
            "controlID": "C-0259",
            "baseScore": 8.0,
            "scanningScope": {
                "matches": [
                    "cluster",
                    "file"
                ]
            },
            "rules": [
                {
                    "name": "rule-credentials-in-env-var",
                    "attributes": {
                        "m$K8sThreatMatrix": "Credential access::Applications credentials in configuration files, Lateral Movement::Applications credentials in configuration files",
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                ""
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Pod"
                            ]
                        },
                        {
                            "apiGroups": [
                                "apps"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet"
                            ]
                        },
                        {
                            "apiGroups": [
                                "batch"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Job",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "configInputs": [
                        "settings.postureControlInputs.sensitiveKeyNames",
                        "settings.postureControlInputs.sensitiveValuesAllowed"
                    ],
                    "controlConfigInputs": [
                        {
                            "path": "settings.postureControlInputs.sensitiveKeyNames",
                            "name": "Keys",
                            "description": "Secrets are stored as a key/value pair. The names of the keys/values may change from one company to the other. Here you can find some examples of popular key phrases that Kubescape is searching for"
                        },
                        {
                            "path": "settings.postureControlInputs.sensitiveValuesAllowed",
                            "name": "AllowedValues",
                            "description": "Allowed values"
                        }
                    ],
                    "description": "fails if Pods have sensitive information in configuration",
                    "remediation": "",
                    "ruleQuery": "armo_builtins",
                    "rule": "\tpackage armo_builtins\n\n\tdeny[msga] {\n\t\tpod := input[_]\n\t\tpod.kind == \"Pod\"\n\t\t# see default-config-inputs.json for list values\n\t\tsensitive_key_names := data.postureControlInputs.sensitiveKeyNames\n\t\tkey_name := sensitive_key_names[_]\n\t\tcontainer := pod.spec.containers[i]\n\t\tenv := container.env[j]\n\n\t\tcontains(lower(env.name), key_name)\n\t\tenv.value != \"\"\n\t\t# check that value wasn't allowed by user\n\t\tnot is_allowed_value(env.value)\n\n\t\tis_not_reference(env)\n\n\t\tpath := sprintf(\"spec.containers[%v].env[%v].name\", [format_int(i, 10), format_int(j, 10)])\n\n\t\tmsga := {\n\t\t\t\"alertMessage\": sprintf(\"Pod: %v has sensitive information in environment variables\", [pod.metadata.name]),\n\t\t\t\"alertScore\": 9,\n\t\t\t\"fixPaths\": [],\n\t\t\t\"failedPaths\": [path],\n\t\t\t\"packagename\": \"armo_builtins\",\n\t\t\t\"alertObject\": {\n\t\t\t\t\"k8sApiObjects\": [pod]\n\t\t\t}\n\t\t}\n\t}\n\n\tdeny[msga] {\n\t\twl := input[_]\n\t\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\t\tspec_template_spec_patterns[wl.kind]\n\n\t\t# see default-config-inputs.json for list values\n\t\tsensitive_key_names := data.postureControlInputs.sensitiveKeyNames\n\t\tkey_name := sensitive_key_names[_]\n\t\tcontainer := wl.spec.template.spec.containers[i]\n\t\tenv := container.env[j]\n\n\t\tcontains(lower(env.name), key_name)\n\t\tenv.value != \"\"\n\t\t# check that value wasn't allowed by user\n\t\tnot is_allowed_value(env.value)\n\n\t\tis_not_reference(env)\n\n\t\tpath := sprintf(\"spec.template.spec.containers[%v].env[%v].name\", [format_int(i, 10), format_int(j, 10)])\n\n\t\tmsga := {\n\t\t\t\"alertMessage\": sprintf(\"%v: %v has sensitive information in environment variables\", [wl.kind, wl.metadata.name]),\n\t\t\t\"alertScore\": 9,\n\t\t\t\"fixPaths\": [],\n\t\t\t\"failedPaths\": [path],\n\t\t\t\"packagename\": \"armo_builtins\",\n\t\t\t\"alertObject\": {\n\t\t\t\t\"k8sApiObjects\": [wl]\n\t\t\t}\n\t\t}\n\t}\n\n\tdeny[msga] {\n\t\twl := input[_]\n\t\twl.kind == \"CronJob\"\n\t\t# see default-config-inputs.json for list values\n\t\tsensitive_key_names := data.postureControlInputs.sensitiveKeyNames\n\t\tkey_name := sensitive_key_names[_]\n\t\tcontainer := wl.spec.jobTemplate.spec.template.spec.containers[i]\n\t\tenv := container.env[j]\n\n\t\tcontains(lower(env.name), key_name)\n\n\t\tenv.value != \"\"\n\t\t# check that value wasn't allowed by user\n\t\tnot is_allowed_value(env.value)\n\n\t\tis_not_reference(env)\n\n\t\tpath := sprintf(\"spec.jobTemplate.spec.template.spec.containers[%v].env[%v].name\", [format_int(i, 10), format_int(j, 10)])\n\n\t\tmsga := {\n\t\t\t\"alertMessage\": sprintf(\"Cronjob: %v has sensitive information in environment variables\", [wl.metadata.name]),\n\t\t\t\"alertScore\": 9,\n\t\t\t\"fixPaths\": [],\n\t\t\t\"failedPaths\": [path],\n\t\t\t\"packagename\": \"armo_builtins\",\n\t\t\t\"alertObject\": {\n\t\t\t\t\"k8sApiObjects\": [wl]\n\t\t\t}\n\t\t}\n\t}\n\n\n\nis_not_reference(env)\n{\n\tnot env.valueFrom.secretKeyRef\n\tnot env.valueFrom.configMapKeyRef\n}\n\nis_allowed_value(value) {\n    allow_val := data.postureControlInputs.sensitiveValuesAllowed[_]\n    value == allow_val\n}"
                }
            ]
        },
        {
            "name": "Workload with configMap access",
            "attributes": {
                "armoBuiltin": true,
                "controlTypeTags": [
                    "security"
                ],
                "attackTracks": [
                    {
                        "attackTrack": "workload-external-track",
                        "categories": [
                            "Data Access"
                        ]
                    }
                ]
            },
            "description": "This control detects workloads that have mounted ConfigMaps. Workloads with ConfigMap access can potentially expose sensitive information and elevate the risk of unauthorized access to critical resources.",
            "remediation": "Review the workloads identified by this control and assess whether it's necessary to mount these configMaps. Remove configMaps access from workloads that don't require it or ensure appropriate access controls are in place to protect sensitive information.",
            "test": "Check if any workload has mounted secrets by inspecting their specifications and verifying if secret volumes are defined",
            "controlID": "C-0258",
            "baseScore": 5.0,
            "scanningScope": {
                "matches": [
                    "cluster",
                    "file"
                ]
            },
            "rules": [
                {
                    "name": "workload-mounted-configmap",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                ""
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Pod",
                                "ConfigMap"
                            ]
                        },
                        {
                            "apiGroups": [
                                "apps"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet"
                            ]
                        },
                        {
                            "apiGroups": [
                                "batch"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Job",
                                "CronJob"
                            ]
                        }
                    ],
                    "description": "fails if workload mounts ConfigMaps",
                    "remediation": "",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\ndeny[msga] {\n\tresource := input[_]\n\tvolumes_path := get_volumes_path(resource)\n\tvolumes := object.get(resource, volumes_path, [])\n\tvolume := volumes[i]\n\tvolume.configMap\n\n\tconfigMap := input[_]\n\tconfigMap.kind == \"ConfigMap\"\n\tconfigMap.metadata.name == volume.configMap.name\n\tis_same_namespace(configMap.metadata, resource.metadata)\n\n\tcontainers_path := get_containers_path(resource)\n\tcontainers := object.get(resource, containers_path, [])\n\tcontainer := containers[j]\n\tcontainer.volumeMounts\n\n \t# check if volume is mounted\n\tcontainer.volumeMounts[_].name == volume.name\n\n\tfailedPaths := sprintf(\"%s[%d].volumeMounts\", [concat(\".\", containers_path), j])\n\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v has mounted configMap\", [resource.kind, resource.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"failedPaths\": [failedPaths],\n\t\t\"fixPaths\":[],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [resource]\n\t\t},\n        \"relatedObjects\": [{\n            \"object\": configMap\n        }]\n\t}\n}\n\n\n\n# get_containers_path - get resource containers paths for  {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\nget_containers_path(resource) := result {\n\tresource_kinds := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tresource_kinds[resource.kind]\n\tresult = [\"spec\", \"template\", \"spec\", \"containers\"]\n}\n\n# get_containers_path - get resource containers paths for \"Pod\"\nget_containers_path(resource) := result {\n\tresource.kind == \"Pod\"\n\tresult = [\"spec\", \"containers\"]\n}\n\n# get_containers_path - get resource containers paths for  \"CronJob\"\nget_containers_path(resource) := result {\n\tresource.kind == \"CronJob\"\n\tresult = [\"spec\", \"jobTemplate\", \"spec\", \"template\", \"spec\", \"containers\"]\n}\n\n# get_volume_path - get resource volumes paths for {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\nget_volumes_path(resource) := result {\n\tresource_kinds := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tresource_kinds[resource.kind]\n\tresult = [\"spec\", \"template\", \"spec\", \"volumes\"]\n}\n\n# get_volumes_path - get resource volumes paths for \"Pod\"\nget_volumes_path(resource) := result {\n\tresource.kind == \"Pod\"\n\tresult = [\"spec\", \"volumes\"]\n}\n\n# get_volumes_path - get resource volumes paths for \"CronJob\"\nget_volumes_path(resource) := result {\n\tresource.kind == \"CronJob\"\n\tresult = [\"spec\", \"jobTemplate\", \"spec\", \"template\", \"spec\", \"volumes\"]\n}\n\n\n\nis_same_namespace(metadata1, metadata2) {\n\tmetadata1.namespace == metadata2.namespace\n}\n\nis_same_namespace(metadata1, metadata2) {\n\tnot metadata1.namespace\n\tnot metadata2.namespace\n}\n\nis_same_namespace(metadata1, metadata2) {\n\tnot metadata2.namespace\n\tmetadata1.namespace == \"default\"\n}\n\nis_same_namespace(metadata1, metadata2) {\n\tnot metadata1.namespace\n\tmetadata2.namespace == \"default\"\n}"
                }
            ]
        },
        {
            "name": "Workload with PVC access",
            "attributes": {
                "armoBuiltin": true,
                "controlTypeTags": [
                    "security"
                ],
                "attackTracks": [
                    {
                        "attackTrack": "workload-external-track",
                        "categories": [
                            "Data Access"
                        ]
                    }
                ]
            },
            "description": "This control detects workloads that have mounted PVC. Workloads with PVC access can potentially expose sensitive information and elevate the risk of unauthorized access to critical resources.",
            "remediation": "Review the workloads identified by this control and assess whether it's necessary to mount these PVCs. Remove PVC access from workloads that don't require it or ensure appropriate access controls are in place to protect sensitive information.",
            "test": "Check if any workload has mounted PVCs by inspecting their specifications and verifying if PVC volumes are defined",
            "controlID": "C-0257",
            "baseScore": 4.0,
            "scanningScope": {
                "matches": [
                    "cluster",
                    "file"
                ]
            },
            "rules": [
                {
                    "name": "workload-mounted-pvc",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                ""
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Pod",
                                "ConfigMap"
                            ]
                        },
                        {
                            "apiGroups": [
                                "apps"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet"
                            ]
                        },
                        {
                            "apiGroups": [
                                "batch"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Job",
                                "CronJob"
                            ]
                        }
                    ],
                    "description": "fails if workload mounts PVC",
                    "remediation": "",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\ndeny[msga] {\n\tresource := input[_]\n\tvolumes_path := get_volumes_path(resource)\n\tvolumes := object.get(resource, volumes_path, [])\n\tvolume := volumes[i]\n\tvolume.persistentVolumeClaim\n\n\tPVC := input[_]\n\tPVC.kind == \"PersistentVolumeClaim\"\n\tPVC.metadata.name == volume.persistentVolumeClaim.claimName\n\tis_same_namespace(PVC.metadata, resource.metadata)\n\n\tcontainers_path := get_containers_path(resource)\n\tcontainers := object.get(resource, containers_path, [])\n\tcontainer := containers[j]\n\tcontainer.volumeMounts\n\n \t# check if volume is mounted\n\tcontainer.volumeMounts[_].name == volume.name\n\n\tfailedPaths := sprintf(\"%s[%d].volumeMounts\", [concat(\".\", containers_path), j])\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v has mounted PVC\", [resource.kind, resource.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"failedPaths\": [failedPaths],\n\t\t\"fixPaths\":[],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [resource]\n\t\t},\n        \"relatedObjects\": [{\n            \"object\": PVC\n        }]\n\t}\n}\n\n\n# get_containers_path - get resource containers paths for  {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\nget_containers_path(resource) := result {\n\tresource_kinds := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tresource_kinds[resource.kind]\n\tresult = [\"spec\", \"template\", \"spec\", \"containers\"]\n}\n\n# get_containers_path - get resource containers paths for \"Pod\"\nget_containers_path(resource) := result {\n\tresource.kind == \"Pod\"\n\tresult = [\"spec\", \"containers\"]\n}\n\n# get_containers_path - get resource containers paths for  \"CronJob\"\nget_containers_path(resource) := result {\n\tresource.kind == \"CronJob\"\n\tresult = [\"spec\", \"jobTemplate\", \"spec\", \"template\", \"spec\", \"containers\"]\n}\n\n# get_volume_path - get resource volumes paths for {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\nget_volumes_path(resource) := result {\n\tresource_kinds := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tresource_kinds[resource.kind]\n\tresult = [\"spec\", \"template\", \"spec\", \"volumes\"]\n}\n\n# get_volumes_path - get resource volumes paths for \"Pod\"\nget_volumes_path(resource) := result {\n\tresource.kind == \"Pod\"\n\tresult = [\"spec\", \"volumes\"]\n}\n\n# get_volumes_path - get resource volumes paths for \"CronJob\"\nget_volumes_path(resource) := result {\n\tresource.kind == \"CronJob\"\n\tresult = [\"spec\", \"jobTemplate\", \"spec\", \"template\", \"spec\", \"volumes\"]\n}\n\n\n\nis_same_namespace(metadata1, metadata2) {\n\tmetadata1.namespace == metadata2.namespace\n}\n\nis_same_namespace(metadata1, metadata2) {\n\tnot metadata1.namespace\n\tnot metadata2.namespace\n}\n\nis_same_namespace(metadata1, metadata2) {\n\tnot metadata2.namespace\n\tmetadata1.namespace == \"default\"\n}\n\nis_same_namespace(metadata1, metadata2) {\n\tnot metadata1.namespace\n\tmetadata2.namespace == \"default\"\n}"
                }
            ]
        },
        {
            "name": "Missing network policy",
            "attributes": {
                "armoBuiltin": true,
                "controlTypeTags": [
                    "security"
                ],
                "attackTracks": [
                    {
                        "attackTrack": "workload-external-track",
                        "categories": [
                            "Network"
                        ]
                    }
                ]
            },
            "description": "This control detects workloads that has no NetworkPolicy configured in labels. If a network policy is not configured, it means that your applications might not have necessary control over the traffic to and from the pods, possibly leading to a security vulnerability.",
            "remediation": "Review the workloads identified by this control and assess whether it's necessary to configure a network policy for them.",
            "test": "Check that all workloads has a network policy configured in labels.",
            "controlID": "C-0260",
            "baseScore": 5.0,
            "scanningScope": {
                "matches": [
                    "cluster",
                    "file"
                ]
            },
            "rules": [
                {
                    "name": "ensure_network_policy_configured_in_labels",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                ""
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Pod",
                                "ConfigMap"
                            ]
                        },
                        {
                            "apiGroups": [
                                "apps"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet"
                            ]
                        },
                        {
                            "apiGroups": [
                                "batch"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Job",
                                "CronJob"
                            ]
                        },
                        {
                            "apiGroups": [
                                "networking.k8s.io"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "NetworkPolicy"
                            ]
                        }
                    ],
                    "description": "fails if no networkpolicy configured in workload labels",
                    "remediation": "",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\n\ndeny[msga] {\n\tworkload := input[_]\n\tworkload_kinds := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\", \"Pod\", \"CronJob\"}\n\tworkload_kinds[workload.kind]\n\n\tnetworkpolicies := [networkpolicy | networkpolicy = input[_]; networkpolicy.kind == \"NetworkPolicy\"]\n\tnot connected_to_any_network_policy(workload, networkpolicies)\n\t\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: no networkpolicy configured in labels\", [workload.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\":[],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [workload]\n\t\t}\n\t}\n}\n\n\nconnected_to_any_network_policy(workload, networkpolicies){\n\tconnected_to_network_policy(workload, networkpolicies[_])\n}\n\n# connected_to_network_policy returns true if the workload is connected to the networkpolicy\nconnected_to_network_policy(wl, networkpolicy){\n\tworkload_kinds := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tworkload_kinds[wl.kind]\n\tis_same_namespace(networkpolicy.metadata, wl.metadata)\n\tcount(networkpolicy.spec.podSelector) > 0\n    count({x | networkpolicy.spec.podSelector.matchLabels[x] == wl.spec.template.metadata.labels[x]}) == count(networkpolicy.spec.podSelector.matchLabels)\n}\n\n# connected_to_network_policy returns true if the workload is connected to the networkpolicy\nconnected_to_network_policy(wl, networkpolicy){\n\twl.kind == \"Pod\"\n\tis_same_namespace(networkpolicy.metadata, wl.metadata)\n    count(networkpolicy.spec.podSelector) > 0\n    count({x | networkpolicy.spec.podSelector.matchLabels[x] == wl.metadata.labels[x]}) == count(networkpolicy.spec.podSelector.matchLabels)\n}\n\n# connected_to_network_policy returns true if the workload is connected to the networkpolicy\nconnected_to_network_policy(wl, networkpolicy){\n\twl.kind == \"CronJob\"\n\tis_same_namespace(networkpolicy.metadata, wl.metadata)\n\tcount(networkpolicy.spec.podSelector) > 0\n    count({x | networkpolicy.spec.podSelector.matchLabels[x] == wl.spec.jobTemplate.spec.template.metadata.labels[x]}) == count(networkpolicy.spec.podSelector.matchLabels)\n}\n\n# connected_to_network_policy returns true if the NetworkPolicy has no podSelector.\n# if the NetworkPolicy has no podSelector, it is applied to all workloads in the namespace of the NetworkPolicy\nconnected_to_network_policy(wl, networkpolicy){\n\tis_same_namespace(networkpolicy.metadata, wl.metadata)\n    count(networkpolicy.spec.podSelector) == 0\n}\n\n\nis_same_namespace(metadata1, metadata2) {\n\tmetadata1.namespace == metadata2.namespace\n}\n\nis_same_namespace(metadata1, metadata2) {\n\tnot metadata1.namespace\n\tnot metadata2.namespace\n}\n\nis_same_namespace(metadata1, metadata2) {\n\tnot metadata2.namespace\n\tmetadata1.namespace == \"default\"\n}\n\nis_same_namespace(metadata1, metadata2) {\n\tnot metadata1.namespace\n\tmetadata2.namespace == \"default\"\n}"
                }
            ]
        },
        {
            "name": "ServiceAccount token mounted",
            "attributes": {
                "armoBuiltin": true,
                "controlTypeTags": [
                    "security"
                ],
                "attackTracks": [
                    {
                        "attackTrack": "workload-external-track",
                        "categories": [
                            "Credential access"
                        ]
                    }
                ]
            },
            "description": "Potential attacker may gain access to a workload and steal its ServiceAccount token. Therefore, it is recommended to disable automatic mapping of the ServiceAccount tokens in ServiceAccount configuration. Enable it only for workloads that need to use them and ensure that this ServiceAccount is not bound to an unnecessary ClusterRoleBinding or RoleBinding.",
            "remediation": "Disable automatic mounting of service account tokens to pods at the workload level, by specifying automountServiceAccountToken: false. Enable it only for workloads that need to use them and ensure that this ServiceAccount doesn't have unnecessary permissions",
            "test": "test if ServiceAccount token is mounted on workload and it has at least one binding.",
            "controlID": "C-0261",
            "baseScore": 7.0,
            "scanningScope": {
                "matches": [
                    "cluster",
                    "file"
                ]
            },
            "rules": [
                {
                    "name": "serviceaccount-token-mount",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                ""
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Pod",
                                "ServiceAccount"
                            ]
                        },
                        {
                            "apiGroups": [
                                "rbac.authorization.k8s.io"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "RoleBinding",
                                "ClusterRoleBinding"
                            ]
                        },
                        {
                            "apiGroups": [
                                "apps"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet"
                            ]
                        },
                        {
                            "apiGroups": [
                                "batch"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Job",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "fails if service account and workloads mount service account token by default",
                    "remediation": "Make sure that the automountServiceAccountToken field on the service account spec if set to false",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\ndeny[msga] {\n    wl := input[_]\n    beggining_of_path := get_beginning_of_path(wl)\n    spec := object.get(wl, beggining_of_path, [])\n\n    wl_namespace := wl.metadata.namespace\n    result := is_sa_auto_mounted(spec, beggining_of_path, wl_namespace)\n    \n    sa := input[_]\n    is_same_sa(spec, sa.metadata.name)\n    is_same_namespace(sa.metadata.namespace , wl_namespace)\n    has_service_account_binding(sa)\n\n    failed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\n    msga := {\n        \"alertMessage\": sprintf(\"%v: %v in the following namespace: %v mounts service account tokens by default\", [wl.kind, wl.metadata.name, wl.metadata.namespace]),\n        \"packagename\": \"armo_builtins\",\n        \"alertScore\": 9,\n        \"fixPaths\": fixed_path,\n        \"failedPaths\": failed_path,\n        \"alertObject\": {\n            \"k8sApiObjects\": [wl]\n        },\n        \"relatedObjects\": [{\n            \"object\": sa\n        }]\n    }\n}\n\n\nget_beginning_of_path(workload) = beggining_of_path {\n    spec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n    spec_template_spec_patterns[workload.kind]\n    beggining_of_path := [\"spec\", \"template\", \"spec\"]\n}\n\nget_beginning_of_path(workload) = beggining_of_path {\n    workload.kind == \"Pod\"\n    beggining_of_path := [\"spec\"]\n}\n\nget_beginning_of_path(workload) = beggining_of_path {\n    workload.kind == \"CronJob\"\n    beggining_of_path := [\"spec\", \"jobTemplate\", \"spec\", \"template\", \"spec\"]\n}\n\n\n #  -- ----     For workloads     -- ----     \nis_sa_auto_mounted(spec, beggining_of_path, wl_namespace) = [failed_path, fix_path]   {\n    # automountServiceAccountToken not in pod spec\n    not spec.automountServiceAccountToken == false\n    not spec.automountServiceAccountToken == true\n\n    fix_path = { \"path\": sprintf(\"%v.automountServiceAccountToken\", [concat(\".\", beggining_of_path)]), \"value\": \"false\"}\n    failed_path = \"\"\n}\n\nis_sa_auto_mounted(spec, beggining_of_path, wl_namespace) =  [failed_path, fix_path]  {\n    # automountServiceAccountToken set to true in pod spec\n    spec.automountServiceAccountToken == true\n\n    failed_path = sprintf(\"%v.automountServiceAccountToken\", [concat(\".\", beggining_of_path)])\n    fix_path = \"\"\n}\n\nget_failed_path(paths) = [paths[0]] {\n    paths[0] != \"\"\n} else = []\n\n\nget_fixed_path(paths) = [paths[1]] {\n    paths[1] != \"\"\n} else = []\n\n\nis_same_sa(spec, serviceAccountName) {\n    spec.serviceAccountName == serviceAccountName\n}\n\nis_same_sa(spec, serviceAccountName) {\n    not spec.serviceAccountName \n    serviceAccountName == \"default\"\n}\n\nis_same_namespace(metadata1, metadata2) {\n    metadata1.namespace == metadata2.namespace\n}\n\nis_same_namespace(metadata1, metadata2) {\n    not metadata1.namespace\n    not metadata2.namespace\n}\n\nis_same_namespace(metadata1, metadata2) {\n    not metadata2.namespace\n    metadata1.namespace == \"default\"\n}\n\nis_same_namespace(metadata1, metadata2) {\n    not metadata1.namespace\n    metadata2.namespace == \"default\"\n}\n\n# checks if RoleBinding/ClusterRoleBinding has a bind with the given ServiceAccount\nhas_service_account_binding(service_account) {\n    role_bindings := [role_binding | role_binding = input[_]; endswith(role_binding.kind, \"Binding\")]\n    role_binding := role_bindings[_]\n    role_binding.subjects[_].name == service_account.metadata.name\n    role_binding.subjects[_].namespace == service_account.metadata.namespace\n    role_binding.subjects[_].kind == \"ServiceAccount\"\n}\n\n# checks if RoleBinding/ClusterRoleBinding has a bind with the system:authenticated group\n# which gives access to all authenticated users, including service accounts\nhas_service_account_binding(service_account) {\n    role_bindings := [role_binding | role_binding = input[_]; endswith(role_binding.kind, \"Binding\")]\n    role_binding := role_bindings[_]\n    role_binding.subjects[_].name == \"system:authenticated\"\n}\n\n# checks if RoleBinding/ClusterRoleBinding has a bind with the \"system:serviceaccounts\" group\n# which gives access to all service accounts\nhas_service_account_binding(service_account) {\n    role_bindings := [role_binding | role_binding = input[_]; endswith(role_binding.kind, \"Binding\")]\n    role_binding := role_bindings[_]\n    role_binding.subjects[_].name == \"system:serviceaccounts\"\n}\n"
                }
            ]
        },
        {
            "name": "Workload with secret access",
            "attributes": {
                "armoBuiltin": true,
                "controlTypeTags": [
                    "security"
                ],
                "attackTracks": [
                    {
                        "attackTrack": "workload-external-track",
                        "categories": [
                            "Secret Access"
                        ]
                    }
                ]
            },
            "description": "This control identifies workloads that have mounted secrets. Workloads with secret access can potentially expose sensitive information and increase the risk of unauthorized access to critical resources.",
            "remediation": "Review the workloads identified by this control and assess whether it's necessary to mount these secrets. Remove secret access from workloads that don't require it or ensure appropriate access controls are in place to protect sensitive information.",
            "test": "Check if any workload has mounted secrets by inspecting their specifications and verifying if secret volumes are defined.",
            "controlID": "C-0255",
            "baseScore": 8.0,
            "scanningScope": {
                "matches": [
                    "cluster",
                    "file"
                ]
            },
            "rules": [
                {
                    "name": "workload-mounted-secrets",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                ""
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Pod",
                                "Secret"
                            ]
                        },
                        {
                            "apiGroups": [
                                "apps"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet"
                            ]
                        },
                        {
                            "apiGroups": [
                                "batch"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Job",
                                "CronJob"
                            ]
                        }
                    ],
                    "description": "fails if workload mounts secrets",
                    "remediation": "",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\ndeny[msga] {\n\tresource := input[_]\n\tvolumes_path := get_volumes_path(resource)\n\tvolumes := object.get(resource, volumes_path, [])\n\tvolume := volumes[i]\n\tvolume.secret\n\n\tsecret := input[_]\n\tsecret.kind == \"Secret\"\n\tsecret.metadata.name == volume.secret.secretName\n\tis_same_namespace(secret.metadata, resource.metadata)\n\n\tcontainers_path := get_containers_path(resource)\n\tcontainers := object.get(resource, containers_path, [])\n\tcontainer := containers[j]\n\tcontainer.volumeMounts\n\n \t# check if volume is mounted\n\tcontainer.volumeMounts[_].name == volume.name\n\n\tfailedPaths := sprintf(\"%s[%d].volumeMounts\", [concat(\".\", containers_path), j])\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v has mounted secret\", [resource.kind, resource.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"failedPaths\": [failedPaths],\n\t\t\"fixPaths\":[],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [resource]\n\t\t},\n        \"relatedObjects\": [{\n            \"object\": secret\n        }]\n\t}\n}\n\n# get_volume_path - get resource volumes paths for {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\nget_volumes_path(resource) := result {\n\tresource_kinds := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tresource_kinds[resource.kind]\n\tresult = [\"spec\", \"template\", \"spec\", \"volumes\"]\n}\n\n# get_containers_path - get resource containers paths for  {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\nget_containers_path(resource) := result {\n\tresource_kinds := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tresource_kinds[resource.kind]\n\tresult = [\"spec\", \"template\", \"spec\", \"containers\"]\n}\n\n# get_containers_path - get resource containers paths for \"Pod\"\nget_containers_path(resource) := result {\n\tresource.kind == \"Pod\"\n\tresult = [\"spec\", \"containers\"]\n}\n\n# get_containers_path - get resource containers paths for  \"CronJob\"\nget_containers_path(resource) := result {\n\tresource.kind == \"CronJob\"\n\tresult = [\"spec\", \"jobTemplate\", \"spec\", \"template\", \"spec\", \"containers\"]\n}\n\n# get_volumes_path - get resource volumes paths for \"Pod\"\nget_volumes_path(resource) := result {\n\tresource.kind == \"Pod\"\n\tresult = [\"spec\", \"volumes\"]\n}\n\n# get_volumes_path - get resource volumes paths for \"CronJob\"\nget_volumes_path(resource) := result {\n\tresource.kind == \"CronJob\"\n\tresult = [\"spec\", \"jobTemplate\", \"spec\", \"template\", \"spec\", \"volumes\"]\n}\n\n\n\nis_same_namespace(metadata1, metadata2) {\n\tmetadata1.namespace == metadata2.namespace\n}\n\nis_same_namespace(metadata1, metadata2) {\n\tnot metadata1.namespace\n\tnot metadata2.namespace\n}\n\nis_same_namespace(metadata1, metadata2) {\n\tnot metadata2.namespace\n\tmetadata1.namespace == \"default\"\n}\n\nis_same_namespace(metadata1, metadata2) {\n\tnot metadata1.namespace\n\tmetadata2.namespace == \"default\"\n}"
                }
            ]
        },
        {
            "name": "HostNetwork access",
            "attributes": {
                "armoBuiltin": true,
                "controlTypeTags": [
                    "security",
                    "compliance"
                ],
                "attackTracks": [
                    {
                        "attackTrack": "container",
                        "categories": [
                            "Discovery",
                            "Lateral movement",
                            "Impact - service access"
                        ]
                    }
                ]
            },
            "description": "Potential attackers may gain access to a POD and inherit access to the entire host network. For example, in AWS case, they will have access to the entire VPC. This control identifies all the PODs with host network access enabled.",
            "remediation": "Only connect PODs to host network when it is necessary. If not, set the hostNetwork field of the pod spec to false, or completely remove it (false is the default). Whitelist only those PODs that must have access to host network by design.",
            "long_description": "We have it in ArmoBest",
            "test": "",
            "controlID": "C-0041",
            "baseScore": 7.0,
            "example": "@controls/examples/c041.yaml",
            "scanningScope": {
                "matches": [
                    "cluster",
                    "file"
                ]
            },
            "rules": [
                {
                    "name": "host-network-access",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                ""
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Pod"
                            ]
                        },
                        {
                            "apiGroups": [
                                "apps"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet"
                            ]
                        },
                        {
                            "apiGroups": [
                                "batch"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Job",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "fails if pod has hostNetwork  enabled",
                    "remediation": "Make sure that the hostNetwork field of the pod spec is not set to true (set to false or not present)",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\n# Fails if pod has hostNetwork enabled\ndeny[msga] {\n    pods := [ pod | pod = input[_] ; pod.kind == \"Pod\"]\n    pod := pods[_]\n\n\tis_host_network(pod.spec)\n\tpath := \"spec.hostNetwork\"\n    msga := {\n\t\"alertMessage\": sprintf(\"Pod: %v is connected to the host network\", [pod.metadata.name]),\n\t\t\"alertScore\": 9,\n\t\t\"failedPaths\": [path],\n\t\t\"fixPaths\":[],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}\n\n# Fails if workload has hostNetwork enabled\ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tis_host_network(wl.spec.template.spec)\n\tpath := \"spec.template.spec.hostNetwork\"\n    msga := {\n\t\"alertMessage\": sprintf(\"%v: %v has a pod connected to the host network\", [wl.kind, wl.metadata.name]),\n\t\t\"alertScore\": 9,\n\t\t\"failedPaths\": [path],\n\t\t\"fixPaths\":[],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n# Fails if cronjob has hostNetwork enabled\ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n\tis_host_network(wl.spec.jobTemplate.spec.template.spec)\n\tpath := \"spec.jobTemplate.spec.template.spec.hostNetwork\"\n    msga := {\n\t\"alertMessage\": sprintf(\"CronJob: %v has a pod connected to the host network\", [wl.metadata.name]),\n\t\t\"alertScore\": 9,\n\t\t\"failedPaths\": [path],\n\t\t\"fixPaths\":[],\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\nis_host_network(podspec) {\n    podspec.hostNetwork == true\n}"
                }
            ]
        },
        {
            "name": "Container hostPort",
            "attributes": {
                "armoBuiltin": true,
                "controlTypeTags": [
                    "security",
                    "compliance",
                    "devops"
                ],
                "attackTracks": [
                    {
                        "attackTrack": "container",
                        "categories": [
                            "Initial access"
                        ]
                    }
                ]
            },
            "description": "Configuring hostPort requires a particular port number. If two objects specify the same HostPort, they could not be deployed to the same node. It may prevent the second object from starting, even if Kubernetes will try reschedule it on another node, provided there are available nodes with sufficient amount of resources. Also, if the number of replicas of such workload is higher than the number of nodes, the deployment will consistently fail.",
            "remediation": "Avoid usage of hostPort unless it is absolutely necessary, in which case define appropriate exception. Use NodePort / ClusterIP instead.",
            "long_description": "Workloads (like pod, deployment, etc) that contain a container with hostport. The problem that arises is that if the scale of your workload is larger than the number of nodes in your Kubernetes cluster, the deployment fails. And any two workloads that specify the same HostPort cannot be deployed to the same node. In addition, if the host where your pods are running becomes unavailable, Kubernetes reschedules the pods to different nodes. Thus, if the IP address for your workload changes, external clients of your application will lose access to the pod. The same thing happens when you restart your pods \u2014 Kubernetes reschedules them to a different node if available.\u00a0",
            "test": "Check for each workload (with container) if it exists inside the container hostPort.\u00a0\u00a0",
            "controlID": "C-0044",
            "baseScore": 4.0,
            "example": "@controls/examples/c044.yaml",
            "scanningScope": {
                "matches": [
                    "cluster",
                    "file"
                ]
            },
            "rules": [
                {
                    "name": "container-hostPort",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                ""
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Pod"
                            ]
                        },
                        {
                            "apiGroups": [
                                "apps"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet"
                            ]
                        },
                        {
                            "apiGroups": [
                                "batch"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Job",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "fails if container has hostPort",
                    "remediation": "Make sure you do not configure hostPort for the container, if necessary use NodePort / ClusterIP",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\n\n# Fails if pod has container with hostPort\ndeny[msga] {\n    pod := input[_]\n    pod.kind == \"Pod\"\n    container := pod.spec.containers[i]\n\tbeggining_of_path := \"spec.\"\n\tpath := is_host_port(container, i, beggining_of_path)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Container: %v has Host-port\", [ container.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 4,\n\t\t\"failedPaths\": path,\n\t\t\"fixPaths\":[],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}\n\n# Fails if workload has container with hostPort\ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n    container := wl.spec.template.spec.containers[i]\n\tbeggining_of_path := \"spec.template.spec.\"\n    path := is_host_port(container, i, beggining_of_path)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Container: %v in %v: %v   has Host-port\", [ container.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 4,\n\t\t\"failedPaths\": path,\n\t\t\"fixPaths\":[],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n# Fails if cronjob has container with hostPort\ndeny[msga] {\n  \twl := input[_]\n\twl.kind == \"CronJob\"\n\tcontainer = wl.spec.jobTemplate.spec.template.spec.containers[i]\n\tbeggining_of_path := \"spec.jobTemplate.spec.template.spec.\"\n    path := is_host_port(container, i, beggining_of_path)\n    msga := {\n\t\t\"alertMessage\": sprintf(\"Container: %v in %v: %v   has Host-port\", [ container.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 4,\n\t\t\"failedPaths\": path,\n\t\t\"fixPaths\":[],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n\n\nis_host_port(container, i, beggining_of_path) = path {\n\tpath = [sprintf(\"%vcontainers[%v].ports[%v].hostPort\", [beggining_of_path, format_int(i, 10), format_int(j, 10)]) | port = container.ports[j];  port.hostPort]\n\tcount(path) > 0\n}\n"
                }
            ]
        },
        {
            "name": "Writable hostPath mount",
            "attributes": {
                "armoBuiltin": true,
                "microsoftMitreColumns": [
                    "Persistence",
                    "Lateral Movement"
                ],
                "controlTypeTags": [
                    "security",
                    "compliance",
                    "devops",
                    "security-impact"
                ],
                "attackTracks": [
                    {
                        "attackTrack": "container",
                        "categories": [
                            "Persistence",
                            "Impact - Data access in container"
                        ]
                    }
                ]
            },
            "description": "Mounting host directory to the container can be used by attackers to get access to the underlying host and gain persistence.",
            "remediation": "Refrain from using the hostPath mount or use the exception mechanism to remove unnecessary notifications.",
            "long_description": "hostPath volume mounts a directory or a file from the host to the container. Attackers who have permissions to create a new container in the cluster may create one with a writable hostPath volume and gain persistence on the underlying host. For example, the latter can be achieved by creating a cron job on the host.",
            "test": "Checking in POD spec if there is a hostPath volume, if it has the section mount.readOnly == false (or doesn\u2019t exist) we raise an alert.",
            "controlID": "C-0045",
            "baseScore": 8.0,
            "example": "@controls/examples/c045.yaml",
            "scanningScope": {
                "matches": [
                    "cluster",
                    "file"
                ]
            },
            "rules": [
                {
                    "name": "alert-rw-hostpath",
                    "attributes": {
                        "m$K8sThreatMatrix": "Persistence::Writable hostPath mount, Lateral Movement::Writable volume mounts on the host",
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                ""
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Pod"
                            ]
                        },
                        {
                            "apiGroups": [
                                "apps"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet"
                            ]
                        },
                        {
                            "apiGroups": [
                                "batch"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Job",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [
                        {
                            "packageName": "cautils"
                        },
                        {
                            "packageName": "kubernetes.api.client"
                        }
                    ],
                    "description": "determines if any workload contains a hostPath volume with rw permissions",
                    "remediation": "Set the readOnly field of the mount to true",
                    "ruleQuery": "",
                    "rule": "package armo_builtins\n\n# Fails if container has a hostPath volume which is not readOnly\n\ndeny[msga] {\n    pod := input[_]\n    pod.kind == \"Pod\"\n    volumes := pod.spec.volumes\n    volume := volumes[_]\n    volume.hostPath\n\tcontainer := pod.spec.containers[i]\n\tvolume_mount := container.volumeMounts[k]\n\tvolume_mount.name == volume.name\n\tbeggining_of_path := \"spec.\"\n\tresult := is_rw_mount(volume_mount, beggining_of_path,  i, k)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\n    podname := pod.metadata.name\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"pod: %v has: %v as hostPath volume\", [podname, volume.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}\n\n#handles majority of workload resources\ndeny[msga] {\n\twl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n    volumes := wl.spec.template.spec.volumes\n    volume := volumes[_]\n    volume.hostPath\n\tcontainer := wl.spec.template.spec.containers[i]\n\tvolume_mount := container.volumeMounts[k]\n\tvolume_mount.name == volume.name\n\tbeggining_of_path := \"spec.template.spec.\"\n\tresult := is_rw_mount(volume_mount, beggining_of_path,  i, k)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v has: %v as hostPath volume\", [wl.kind, wl.metadata.name, volume.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"failedPaths\": failed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t\n\t}\n}\n\n#handles CronJobs\ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n    volumes := wl.spec.jobTemplate.spec.template.spec.volumes\n    volume := volumes[_]\n    volume.hostPath\n\n\tcontainer = wl.spec.jobTemplate.spec.template.spec.containers[i]\n\tvolume_mount := container.volumeMounts[k]\n\tvolume_mount.name == volume.name\n\tbeggining_of_path := \"spec.jobTemplate.spec.template.spec.\"\n\tresult := is_rw_mount(volume_mount, beggining_of_path,  i, k) \n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\n\n\tmsga := {\n\t\"alertMessage\": sprintf(\"%v: %v has: %v as hostPath volume\", [wl.kind, wl.metadata.name, volume.name]),\n\t\"packagename\": \"armo_builtins\",\n\t\"alertScore\": 7,\n\t\"fixPaths\": fixed_path,\n\t\"failedPaths\": failed_path,\n\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\nget_failed_path(paths) = [paths[0]] {\n\tpaths[0] != \"\"\n} else = []\n\n\nget_fixed_path(paths) = [paths[1]] {\n\tpaths[1] != \"\"\n} else = []\n\n\nis_rw_mount(mount, beggining_of_path,  i, k) =  [failed_path, fix_path] {\n\tnot mount.readOnly == true\n \tnot mount.readOnly == false\n\tfailed_path = \"\"\n    fix_path = {\"path\": sprintf(\"%vcontainers[%v].volumeMounts[%v].readOnly\", [beggining_of_path, format_int(i, 10), format_int(k, 10)]), \"value\":\"true\"}\n}\n\nis_rw_mount(mount, beggining_of_path,  i, k) =  [failed_path, fix_path] {\n  \tmount.readOnly == false\n  \tfailed_path = sprintf(\"%vcontainers[%v].volumeMounts[%v].readOnly\", [beggining_of_path, format_int(i, 10), format_int(k, 10)])\n    fix_path = \"\"\n} "
                }
            ]
        },
        {
            "name": "Insecure capabilities",
            "attributes": {
                "actionRequired": "configuration",
                "armoBuiltin": true,
                "controlTypeTags": [
                    "security",
                    "compliance"
                ],
                "attackTracks": [
                    {
                        "attackTrack": "container",
                        "categories": [
                            "Privilege escalation"
                        ]
                    }
                ]
            },
            "description": "Giving insecure or excessive capabilities to a container can increase the impact of the container compromise. This control identifies all the PODs with dangerous capabilities (see documentation pages for details).",
            "remediation": "Remove all insecure capabilities which are not necessary for the container.",
            "long_description": "Giving  insecure and unnecessary capabilities for a container can increase the impact of a container compromise.",
            "test": "Check capabilities given against a configurable blacklist of insecure capabilities (https://man7.org/linux/man-pages/man7/capabilities.7.html). ",
            "controlID": "C-0046",
            "baseScore": 7.0,
            "example": "@controls/examples/c046.yaml",
            "scanningScope": {
                "matches": [
                    "cluster",
                    "file"
                ]
            },
            "rules": [
                {
                    "name": "insecure-capabilities",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                ""
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Pod"
                            ]
                        },
                        {
                            "apiGroups": [
                                "apps"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet"
                            ]
                        },
                        {
                            "apiGroups": [
                                "batch"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Job",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "configInputs": [
                        "settings.postureControlInputs.insecureCapabilities"
                    ],
                    "controlConfigInputs": [
                        {
                            "path": "settings.postureControlInputs.insecureCapabilities",
                            "name": "Insecure capabilities",
                            "description": "You can see the list of capabilities in https://man7.org/linux/man-pages/man7/capabilities.7.html. Kubescape looks for the following capabilities in containers which might lead to attackers getting high privileges in your system."
                        }
                    ],
                    "description": "fails if container has insecure capabilities",
                    "remediation": "Remove all insecure capabilities which aren\u2019t necessary for the container.",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\nimport data.cautils\n\ndeny[msga] {\n    pod := input[_]\n    pod.kind == \"Pod\"\n\tcontainer := pod.spec.containers[i]\n\tbeggining_of_path := \"spec.\"\n    result := is_dangerous_capabilities(container, beggining_of_path, i)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"container: %v in pod: %v  have dangerous capabilities\", [container.name, pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": result,\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}\n\ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n\tcontainer := wl.spec.template.spec.containers[i]\n\tbeggining_of_path := \"spec.template.spec.\"\n    result := is_dangerous_capabilities(container, beggining_of_path, i)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"container: %v in workload: %v  have dangerous capabilities\", [container.name, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": result,\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\ndeny[msga] {\n    wl := input[_]\n\twl.kind == \"CronJob\"\n\tcontainer := wl.spec.jobTemplate.spec.template.spec.containers[i]\n\tbeggining_of_path := \"spec.jobTemplate.spec.template.spec.\"\n    result := is_dangerous_capabilities(container, beggining_of_path, i)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"container: %v in cronjob: %v  have dangerous capabilities\", [container.name, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": result,\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\nis_dangerous_capabilities(container, beggining_of_path, i) = path {\n\t# see default-config-inputs.json for list values\n    insecureCapabilities := data.postureControlInputs.insecureCapabilities\n\tpath = [sprintf(\"%vcontainers[%v].securityContext.capabilities.add[%v]\", [beggining_of_path, format_int(i, 10), format_int(k, 10)]) | capability = container.securityContext.capabilities.add[k]; cautils.list_contains(insecureCapabilities, capability)]\n\tcount(path) > 0\n}"
                }
            ]
        },
        {
            "name": "HostPath mount",
            "attributes": {
                "armoBuiltin": true,
                "microsoftMitreColumns": [
                    "Privilege escalation"
                ],
                "controlTypeTags": [
                    "security",
                    "compliance"
                ],
                "attackTracks": [
                    {
                        "attackTrack": "container",
                        "categories": [
                            "Impact - Data access in container"
                        ]
                    }
                ]
            },
            "description": "Mounting host directory to the container can be used by attackers to get access to the underlying host. This control identifies all the PODs using hostPath mount.",
            "example": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-pd\nspec:\n  containers:\n  - image: k8s.gcr.io/test-webserver\n    name: test-container\n    volumeMounts:\n    - mountPath: /test-pd\n      name: test-volume\n  volumes:\n  - name: test-volume\n    hostPath: # This field triggers failure!\n      path: /data\n      type: Directory\n",
            "remediation": "Remove hostPath mounts unless they are absolutely necessary and use exception mechanism to remove notifications.",
            "controlID": "C-0048",
            "baseScore": 7.0,
            "scanningScope": {
                "matches": [
                    "cluster",
                    "file"
                ]
            },
            "rules": [
                {
                    "name": "alert-any-hostpath",
                    "attributes": {
                        "m$K8sThreatMatrix": "Privilege Escalation::hostPath mount",
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                ""
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Pod"
                            ]
                        },
                        {
                            "apiGroups": [
                                "apps"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet"
                            ]
                        },
                        {
                            "apiGroups": [
                                "batch"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Job",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "determines if any workload contains a hostPath volume",
                    "remediation": "Try to refrain from using hostPath mounts",
                    "ruleQuery": "",
                    "rule": "package armo_builtins\n\n\ndeny[msga] {\n    pod := input[_]\n    pod.kind == \"Pod\"\n    volumes := pod.spec.volumes\n    volume := volumes[i]\n\tbeggining_of_path := \"spec.\"\n\tresult  := is_dangerous_host_path(volume, beggining_of_path, i)\n    podname := pod.metadata.name\n\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"pod: %v has: %v as hostPath volume\", [podname, volume.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [result],\n\t\t\"fixPaths\":[],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}\n\n#handles majority of workload resources\ndeny[msga] {\n\twl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n    volumes := wl.spec.template.spec.volumes\n    volume := volumes[i]\n\tbeggining_of_path := \"spec.template.spec.\"\n    result  := is_dangerous_host_path(volume, beggining_of_path, i)\n\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v has: %v as hostPath volume\", [wl.kind, wl.metadata.name, volume.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [result],\n\t\t\"fixPaths\":[],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n#handles CronJobs\ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n    volumes := wl.spec.jobTemplate.spec.template.spec.volumes\n    volume := volumes[i]\n\tbeggining_of_path := \"spec.jobTemplate.spec.template.spec.\"\n    result  := is_dangerous_host_path(volume, beggining_of_path, i)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v has: %v as hostPath volume\", [wl.kind, wl.metadata.name, volume.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [result],\n\t\t\"fixPaths\":[],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n\n\nis_dangerous_host_path(volume, beggining_of_path, i) = path {\n    startswith(volume.hostPath.path, \"/etc\")\n\tpath = sprintf(\"%vvolumes[%v].hostPath.path\", [beggining_of_path, format_int(i, 10)])\n}\n\nis_dangerous_host_path(volume, beggining_of_path, i) = path {\n    startswith(volume.hostPath.path, \"/var\")\n\tpath = sprintf(\"%vvolumes[%v].hostPath.path\", [beggining_of_path, format_int(i, 10)])\n}"
                }
            ]
        },
        {
            "name": "Apply Security Context to Your Pods and Containers",
            "controlID": "C-0211",
            "description": "Apply Security Context to Your Pods and Containers",
            "long_description": "A security context defines the operating system security settings (uid, gid, capabilities, SELinux role, etc..) applied to a container. When designing your containers and pods, make sure that you configure the security context for your pods, containers, and volumes. A security context is a property defined in the deployment yaml. It controls the security parameters that will be assigned to the pod/container/volume. There are two levels of security context: pod level security context, and container level security context.",
            "remediation": "Follow the Kubernetes documentation and apply security contexts to your pods. For a suggested list of security contexts, you may refer to the CIS Security Benchmark for Docker Containers.",
            "test": "Check that pod and container security context fields according to recommendations in CIS Security Benchmark for Docker Containers",
            "manual_test": "Review the pod definitions in your cluster and verify that you have security contexts defined as appropriate.",
            "references": [
                "https://workbench.cisecurity.org/sections/1126667/recommendations/1838636"
            ],
            "attributes": {
                "armoBuiltin": true
            },
            "baseScore": 8,
            "impact_statement": "If you incorrectly apply security contexts, you may have trouble running the pods.",
            "default_value": "By default, no security contexts are automatically applied to pods.",
            "scanningScope": {
                "matches": [
                    "cloud"
                ]
            },
            "rules": [
                {
                    "name": "rule-privilege-escalation",
                    "attributes": {
                        "m$K8sThreatMatrix": "Privilege Escalation::privileged container",
                        "mitre": "Privilege Escalation",
                        "mitreCode": "TA0004",
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                ""
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Pod"
                            ]
                        },
                        {
                            "apiGroups": [
                                "apps"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet"
                            ]
                        },
                        {
                            "apiGroups": [
                                "batch"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Job",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "determines if pods/deployments defined as privileged true",
                    "remediation": "avoid defining pods as privilleged",
                    "ruleQuery": "",
                    "rule": "package armo_builtins\n# Deny mutating action unless user is in group owning the resource\n\n\n#privileged pods\ndeny[msga] {\n\n\tpod := input[_]\n\tpod.kind == \"Pod\"\n\tcontainer := pod.spec.containers[i]\n\tbeggining_of_path := \"spec.\"\n\tpath := isPrivilegedContainer(container, i, beggining_of_path)\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"the following pods are defined as privileged: %v\", [pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"fixPaths\": [],\n\t\t\"failedPaths\": path,\n         \"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n     }\n}\n\n\n#handles majority of workload resources\ndeny[msga] {\n\twl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n\tcontainer := wl.spec.template.spec.containers[i]\n\tbeggining_of_path := \"spec.template.spec.\"\n\tpath := isPrivilegedContainer(container, i, beggining_of_path)\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"%v: %v is defined as privileged:\", [wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"fixPaths\": [],\n\t\t\"failedPaths\": path,\n         \"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n     }\n}\n\n#handles cronjob\ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n\tcontainer := wl.spec.jobTemplate.spec.template.spec.containers[i]\n\tbeggining_of_path := \"spec.jobTemplate.spec.template.spec.\"\n\tpath := isPrivilegedContainer(container, i, beggining_of_path)\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"the following cronjobs are defined as privileged: %v\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 3,\n\t\t\"fixPaths\": [],\n\t\t\"failedPaths\": path,\n         \"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n     }\n}\n\n\n# Only SYS_ADMIN capabilite\nisPrivilegedContainer(container, i, beggining_of_path) = path {\n\tnot container.securityContext.privileged == true\n\tpath = [sprintf(\"%vcontainers[%v].securityContext.capabilities.add[%v]\", [beggining_of_path, format_int(i, 10), format_int(k, 10)]) | capabilite = container.securityContext.capabilities.add[k]; capabilite == \"SYS_ADMIN\"]\n\tcount(path) > 0\n}\n\n# Only securityContext.privileged == true\nisPrivilegedContainer(container, i, beggining_of_path) = path {\n\tcontainer.securityContext.privileged == true\n\tpath1 = [sprintf(\"%vcontainers[%v].securityContext.capabilities.add[%v]\", [beggining_of_path, format_int(i, 10), format_int(k, 10)]) | capabilite = container.securityContext.capabilities.add[k]; capabilite == \"SYS_ADMIN\"]\n\tcount(path1) < 1\n\tpath = [sprintf(\"%vcontainers[%v].securityContext.privileged\", [beggining_of_path, format_int(i, 10)])]\n}\n\n# SYS_ADMIN capabilite && securityContext.privileged == true\nisPrivilegedContainer(container, i, beggining_of_path) = path {\n\tpath1 = [sprintf(\"%vcontainers[%v].securityContext.capabilities.add[%v]\", [beggining_of_path, format_int(i, 10), format_int(k, 10)]) | capabilite = container.securityContext.capabilities.add[k]; capabilite == \"SYS_ADMIN\"]\n\tcount(path1) > 0\n\tcontainer.securityContext.privileged == true\n\tpath = array.concat(path1, [sprintf(\"%vcontainers[%v].securityContext.privileged\", [beggining_of_path, format_int(i, 10)])])\n}"
                },
                {
                    "name": "immutable-container-filesystem",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                ""
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Pod"
                            ]
                        },
                        {
                            "apiGroups": [
                                "apps"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet"
                            ]
                        },
                        {
                            "apiGroups": [
                                "batch"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Job",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "fails if container has mutable filesystem",
                    "remediation": "Make sure that the securityContext.readOnlyRootFilesystem field in the container/pod spec is set to true",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\n\n# Fails if pods has container with mutable filesystem\ndeny[msga] {\n    pod := input[_]\n    pod.kind == \"Pod\"\n\tcontainer := pod.spec.containers[i]\n\tbeggining_of_path := \"spec.\"\n    result := is_mutable_filesystem(container, beggining_of_path, i)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"container: %v in pod: %v  has  mutable filesystem\", [container.name, pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": failed_path,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}\n\n# Fails if workload has  container with mutable filesystem \ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n    container := wl.spec.template.spec.containers[i]\n\tbeggining_of_path := \"spec.template.spec.\"\n    result := is_mutable_filesystem(container, beggining_of_path, i)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"container :%v in %v: %v has  mutable filesystem\", [container.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": failed_path,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n\n# Fails if cronjob has  container with mutable filesystem \ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n\tcontainer = wl.spec.jobTemplate.spec.template.spec.containers[i]\n\tbeggining_of_path := \"spec.jobTemplate.spec.template.spec.\"\n\tresult := is_mutable_filesystem(container, beggining_of_path, i)\n\tfailed_path := get_failed_path(result)\n    fixed_path := get_fixed_path(result)\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"container :%v in %v: %v has mutable filesystem\", [container.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": failed_path,\n\t\t\"fixPaths\": fixed_path,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n# Default of readOnlyRootFilesystem is false. This field is only in container spec and not pod spec\nis_mutable_filesystem(container, beggining_of_path, i) = [failed_path, fixPath]  {\n\tcontainer.securityContext.readOnlyRootFilesystem == false\n\tfailed_path = sprintf(\"%vcontainers[%v].securityContext.readOnlyRootFilesystem\", [beggining_of_path, format_int(i, 10)])\n\tfixPath = \"\"\n }\n\n is_mutable_filesystem(container, beggining_of_path, i)  = [failed_path, fixPath] {\n\tnot container.securityContext.readOnlyRootFilesystem == false\n    not container.securityContext.readOnlyRootFilesystem == true\n\tfixPath = {\"path\": sprintf(\"%vcontainers[%v].securityContext.readOnlyRootFilesystem\", [beggining_of_path, format_int(i, 10)]), \"value\": \"true\"}\n\tfailed_path = \"\"\n }\n\n\n get_failed_path(paths) = [paths[0]] {\n\tpaths[0] != \"\"\n} else = []\n\n\nget_fixed_path(paths) = [paths[1]] {\n\tpaths[1] != \"\"\n} else = []\n"
                },
                {
                    "name": "non-root-containers",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                ""
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Pod"
                            ]
                        },
                        {
                            "apiGroups": [
                                "apps"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet"
                            ]
                        },
                        {
                            "apiGroups": [
                                "batch"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Job",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "fails if container can run as root",
                    "remediation": "Make sure that the user/group in the securityContext of pod/container is set to an id less than 1000, or the runAsNonRoot flag is set to true. Also make sure that the allowPrivilegeEscalation field is set to false",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\n\n################################################################################\n# Rules\ndeny[msga] {\n    pod := input[_]\n    pod.kind == \"Pod\"\n\tcontainer := pod.spec.containers[i]\n\n\tbeggining_of_path := \"spec\"\n\talertInfo := evaluate_workload_non_root_container(container, pod, beggining_of_path)\n\tfixPath := get_fixed_path(alertInfo, i)\n    failed_path := get_failed_path(alertInfo, i) \n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"container: %v in pod: %v  may run as root\", [container.name, pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": failed_path,\n        \"fixPaths\": fixPath,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n\t}\n}\n\n\ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n    container := wl.spec.template.spec.containers[i]\n\n\tbeggining_of_path := \"spec.template.spec\"\n\talertInfo := evaluate_workload_non_root_container(container, wl.spec.template, beggining_of_path)\n\tfixPath := get_fixed_path(alertInfo, i)\n    failed_path := get_failed_path(alertInfo, i) \n    msga := {\n\t\t\"alertMessage\": sprintf(\"container :%v in %v: %v may run as root\", [container.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": failed_path,\n        \"fixPaths\": fixPath,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n# Fails if cronjob has a container configured to run as root\ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n\tcontainer = wl.spec.jobTemplate.spec.template.spec.containers[i]\n\n\tbeggining_of_path := \"spec.jobTemplate.spec.template.spec\"\n\talertInfo := evaluate_workload_non_root_container(container, wl.spec.jobTemplate.spec.template, beggining_of_path)\n\tfixPath := get_fixed_path(alertInfo, i)\n    failed_path := get_failed_path(alertInfo, i) \n\t\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"container :%v in %v: %v  may run as root\", [container.name, wl.kind, wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": failed_path,\n        \"fixPaths\": fixPath,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\nget_failed_path(alertInfo, i) = [replace(alertInfo.failed_path,\"container_ndx\",format_int(i,10))] {\n\talertInfo.failed_path != \"\"\n} else = []\n\n\nget_fixed_path(alertInfo, i) = [{\"path\":replace(alertInfo.fixPath[0].path,\"container_ndx\",format_int(i,10)), \"value\":alertInfo.fixPath[0].value}, {\"path\":replace(alertInfo.fixPath[1].path,\"container_ndx\",format_int(i,10)), \"value\":alertInfo.fixPath[1].value}]{\n\tcount(alertInfo.fixPath) == 2\n} else = [{\"path\":replace(alertInfo.fixPath[0].path,\"container_ndx\",format_int(i,10)), \"value\":alertInfo.fixPath[0].value}] {\n\tcount(alertInfo.fixPath) == 1\n}  else = []\n\n#################################################################################\n# Workload evaluation \n\nevaluate_workload_non_root_container(container, pod, beggining_of_path) = alertInfo {\n\trunAsNonRootValue := get_run_as_non_root_value(container, pod, beggining_of_path)\n\trunAsNonRootValue.value == false\n\t\n\trunAsUserValue := get_run_as_user_value(container, pod, beggining_of_path)\n\trunAsUserValue.value == 0\n\n\talertInfo := choose_first_if_defined(runAsUserValue, runAsNonRootValue)\n} else = alertInfo {\n    allowPrivilegeEscalationValue := get_allow_privilege_escalation(container, pod, beggining_of_path)\n    allowPrivilegeEscalationValue.value == true\n\n    alertInfo := allowPrivilegeEscalationValue\n}\n\n\n#################################################################################\n# Value resolution functions\n\n\nget_run_as_non_root_value(container, pod, beggining_of_path) = runAsNonRoot {\n    failed_path := sprintf(\"%v.containers[container_ndx].securityContext.runAsNonRoot\", [beggining_of_path]) \n    runAsNonRoot := {\"value\" : container.securityContext.runAsNonRoot, \"failed_path\" : failed_path, \"fixPath\": [] ,\"defined\" : true}\n} else = runAsNonRoot {\n\tfailed_path := sprintf(\"%v.securityContext.runAsNonRoot\", [beggining_of_path]) \n    runAsNonRoot := {\"value\" : pod.spec.securityContext.runAsNonRoot,  \"failed_path\" : failed_path, \"fixPath\": [], \"defined\" : true}\n} else = {\"value\" : false,  \"failed_path\" : \"\", \"fixPath\": [{\"path\": sprintf(\"%v.containers[container_ndx].securityContext.runAsNonRoot\", [beggining_of_path]), \"value\":\"true\"}], \"defined\" : false} {\n\tis_allow_privilege_escalation_field(container, pod)\n} else = {\"value\" : false,  \"failed_path\" : \"\", \"fixPath\": [{\"path\":  sprintf(\"%v.containers[container_ndx].securityContext.runAsNonRoot\", [beggining_of_path]) , \"value\":\"true\"}, {\"path\":sprintf(\"%v.containers[container_ndx].securityContext.allowPrivilegeEscalation\", [beggining_of_path]), \"value\":\"false\"}], \"defined\" : false}\n\nget_run_as_user_value(container, pod, beggining_of_path) = runAsUser {\n\tfailed_path := sprintf(\"%v.containers[container_ndx].securityContext.runAsUser\", [beggining_of_path]) \n    runAsUser := {\"value\" : container.securityContext.runAsUser,  \"failed_path\" : failed_path,  \"fixPath\": [], \"defined\" : true}\n} else = runAsUser {\n\tfailed_path := sprintf(\"%v.securityContext.runAsUser\", [beggining_of_path]) \n    runAsUser := {\"value\" : pod.spec.securityContext.runAsUser,  \"failed_path\" : failed_path, \"fixPath\": [],\"defined\" : true}\n} else = {\"value\" : 0, \"failed_path\": \"\", \"fixPath\": [{\"path\":  sprintf(\"%v.containers[container_ndx].securityContext.runAsNonRoot\", [beggining_of_path]), \"value\":\"true\"}],\"defined\" : false}{\n\tis_allow_privilege_escalation_field(container, pod)\n} else = {\"value\" : 0, \"failed_path\": \"\", \n\t\"fixPath\": [{\"path\":  sprintf(\"%v.containers[container_ndx].securityContext.runAsNonRoot\", [beggining_of_path]), \"value\":\"true\"},{\"path\":  sprintf(\"%v.containers[container_ndx].securityContext.allowPrivilegeEscalation\", [beggining_of_path]), \"value\":\"false\"}],\n\t\"defined\" : false}\n\nget_run_as_group_value(container, pod, beggining_of_path) = runAsGroup {\n\tfailed_path := sprintf(\"%v.containers[container_ndx].securityContext.runAsGroup\", [beggining_of_path])\n    runAsGroup := {\"value\" : container.securityContext.runAsGroup,  \"failed_path\" : failed_path, \"fixPath\": [],\"defined\" : true}\n} else = runAsGroup {\n\tfailed_path := sprintf(\"%v.securityContext.runAsGroup\", [beggining_of_path])\n    runAsGroup := {\"value\" : pod.spec.securityContext.runAsGroup,  \"failed_path\" : failed_path, \"fixPath\":[], \"defined\" : true}\n} else = {\"value\" : 0, \"failed_path\": \"\", \"fixPath\": [{\"path\": sprintf(\"%v.containers[container_ndx].securityContext.runAsNonRoot\", [beggining_of_path]), \"value\":\"true\"}], \"defined\" : false}{\n\tis_allow_privilege_escalation_field(container, pod)\n} else = {\"value\" : 0, \"failed_path\": \"\", \n\t\"fixPath\": [{\"path\": sprintf(\"%v.containers[container_ndx].securityContext.runAsNonRoot\", [beggining_of_path]), \"value\":\"true\"},{\"path\": sprintf(\"%v.containers[container_ndx].securityContext.allowPrivilegeEscalation\", [beggining_of_path]), \"value\":\"false\"}],\n \t\"defined\" : false\n}\n\nget_allow_privilege_escalation(container, pod, beggining_of_path) = allowPrivilegeEscalation {\n\tfailed_path := sprintf(\"%v.containers[container_ndx].securityContext.allowPrivilegeEscalation\", [beggining_of_path])\n    allowPrivilegeEscalation := {\"value\" : container.securityContext.allowPrivilegeEscalation,  \"failed_path\" : failed_path, \"fixPath\": [],\"defined\" : true}\n} else = allowPrivilegeEscalation {\n\tfailed_path := sprintf(\"%v.securityContext.allowPrivilegeEscalation\", [beggining_of_path])\n    allowPrivilegeEscalation := {\"value\" : pod.spec.securityContext.allowPrivilegeEscalation,  \"failed_path\" : failed_path, \"fixPath\": [],\"defined\" : true}\n} else = {\"value\" : true, \"failed_path\": \"\", \"fixPath\": [{\"path\": sprintf(\"%v.containers[container_ndx].securityContext.allowPrivilegeEscalation\", [beggining_of_path]), \"value\":\"false\"}], \"defined\" : false}\n\nchoose_first_if_defined(l1, l2) = c {\n    l1.defined\n    c := l1\n} else = l2\n\n\nis_allow_privilege_escalation_field(container, pod) {\n\tcontainer.securityContext.allowPrivilegeEscalation == false\n}\n\nis_allow_privilege_escalation_field(container, pod) {\n\tpod.spec.securityContext.allowPrivilegeEscalation == false\n}\n\n\n"
                },
                {
                    "name": "drop-capability-netraw",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                ""
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Pod"
                            ]
                        },
                        {
                            "apiGroups": [
                                "apps"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet"
                            ]
                        },
                        {
                            "apiGroups": [
                                "batch"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Job",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "fails if container does not drop the capability NET_RAW",
                    "remediation": "Define the drop list in security context capabilities to include NET_RAW.",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\nimport future.keywords.in\n\n# Fails if pod does not drop the capability NET_RAW \ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"Pod\"\n\tpath_to_containers := [\"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n\n\tpath_to_search := [\"securityContext\", \"capabilities\"]\n\tresult := container_doesnt_drop_NET_RAW(container, i, path_to_containers, path_to_search)\n\tfailedPaths := get_failed_path(result)\n    fixPaths := get_fixed_path(result)\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Pod: %s does not drop the capability NET_RAW\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": failedPaths,\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\"k8sApiObjects\": [wl]},\n\t}\n}\n\n# Fails if workload does not drop the capability NET_RAW\ndeny[msga] {\n\twl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\", \"ReplicaSet\", \"DaemonSet\", \"StatefulSet\", \"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n\tpath_to_containers := [\"spec\", \"template\", \"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n\n\tpath_to_search := [\"securityContext\", \"capabilities\"]\n\tresult := container_doesnt_drop_NET_RAW(container, i, path_to_containers, path_to_search)\n\tfailedPaths := get_failed_path(result)\n    fixPaths := get_fixed_path(result)\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Workload: %v does not drop the capability NET_RAW\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": failedPaths,\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\"k8sApiObjects\": [wl]},\n\t}\n}\n\n# Fails if CronJob does not drop the capability NET_RAW\ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n\tpath_to_containers := [\"spec\", \"jobTemplate\", \"spec\", \"template\", \"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n\n\tpath_to_search := [\"securityContext\", \"capabilities\"]\n\tresult := container_doesnt_drop_NET_RAW(container, i, path_to_containers, path_to_search)\n\tfailedPaths := get_failed_path(result)\n    fixPaths := get_fixed_path(result)\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Cronjob: %v does not drop the capability NET_RAW\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": failedPaths,\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\"k8sApiObjects\": [wl]},\n\t}\n}\n\n# Checks if workload does not drop the capability NET_RAW\ncontainer_doesnt_drop_NET_RAW(container, i, path_to_containers, path_to_search) = [failed_path, fix_path] {\n\tpath_to_drop := array.concat(path_to_search, [\"drop\"])\n\tdrop_list := object.get(container, path_to_drop, [])\n\tnot \"NET_RAW\" in drop_list\n\tnot \"ALL\" in drop_list\n\tnot \"all\" in drop_list\n\tfixpath := sprintf(\"%s[%d].%s[%d]\", [concat(\".\", path_to_containers), i, concat(\".\", path_to_drop), count(drop_list)])\n\tfix_path := [{\"path\": fixpath, \"value\": \"NET_RAW\"}]\n\tfailed_path := \"\"\n}\n\n# Checks if workload drops all capabilities but adds NET_RAW capability\ncontainer_doesnt_drop_NET_RAW(container, i, path_to_containers, path_to_search) = [failed_path, fix_path] {\n\tpath_to_drop := array.concat(path_to_search, [\"drop\"])\n\tdrop_list := object.get(container, path_to_drop, [])\n\tall_in_list(drop_list)\n\tpath_to_add := array.concat(path_to_search, [\"add\"])\n\tadd_list := object.get(container, path_to_add, [])\n\t\"NET_RAW\" in add_list\n\tfailed_path := [sprintf(\"%s[%d].%s\", [concat(\".\", path_to_containers), i, concat(\".\", path_to_add)])]\n\tfix_path := \"\"\n}\n\nall_in_list(list) {\n\t\"all\" in list\n}\n\nall_in_list(list) {\n\t\"ALL\" in list\n}\n\n\nget_failed_path(paths) = paths[0] {\n\tpaths[0] != \"\"\n} else = []\n\n\nget_fixed_path(paths) = paths[1] {\n\tpaths[1] != \"\"\n} else = []\n\n"
                },
                {
                    "name": "set-seLinuxOptions",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                ""
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Pod"
                            ]
                        },
                        {
                            "apiGroups": [
                                "apps"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet"
                            ]
                        },
                        {
                            "apiGroups": [
                                "batch"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Job",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "fails if workload and container do not define any seLinuxOptions",
                    "remediation": "Make sure you set seLinuxOptions in the workload/container security context.",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\n\n# Fails if pod does not define seLinuxOptions \ndeny[msga] {\n    wl := input[_]\n    wl.kind == \"Pod\"\n    spec := wl.spec\n\tpath_to_search := [\"securityContext\", \"seLinuxOptions\"]\n\tno_seLinuxOptions_in_securityContext(spec, path_to_search)\n\n\tpath_to_containers := [\"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n    no_seLinuxOptions_in_securityContext(container, path_to_search)\n\n\tfix_path := sprintf(\"%s[%d].%s\", [concat(\".\", path_to_containers), i, concat(\".\", path_to_search)]) \n\tfixPaths := [{\"path\": fix_path, \"value\": \"YOUR_VALUE\"}]\n\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Pod: %v does not define any seLinuxOptions\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n# Fails if workload does not define seLinuxOptions\ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n    spec := wl.spec.template.spec\n\tpath_to_search := [\"securityContext\", \"seLinuxOptions\"]\n\tno_seLinuxOptions_in_securityContext(spec, path_to_search)\n\n\tpath_to_containers := [\"spec\", \"template\", \"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n    no_seLinuxOptions_in_securityContext(container, path_to_search)\n\n\tfix_path := sprintf(\"%s[%d].%s\", [concat(\".\", path_to_containers), i, concat(\".\", path_to_search)]) \n\tfixPaths := [{\"path\": fix_path, \"value\": \"YOUR_VALUE\"}]\n\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Workload: %v does not define any seLinuxOptions\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n\n# Fails if CronJob does not define seLinuxOptions \ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n\tspec := wl.spec.jobTemplate.spec.template.spec\n\tpath_to_search := [\"securityContext\", \"seLinuxOptions\"]\n\tno_seLinuxOptions_in_securityContext(spec, path_to_search)\n\n\tpath_to_containers := [\"spec\", \"jobTemplate\", \"spec\", \"template\", \"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n    no_seLinuxOptions_in_securityContext(container, path_to_search)\n\n\tfix_path := sprintf(\"%s[%d].%s\", [concat(\".\", path_to_containers), i, concat(\".\", path_to_search)]) \n\tfixPaths := [{\"path\": fix_path, \"value\": \"YOUR_VALUE\"}]\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Cronjob: %v does not define any seLinuxOptions\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\nno_seLinuxOptions_in_securityContext(spec, path_to_search){\n    object.get(spec, path_to_search, \"\") == \"\"\n}"
                },
                {
                    "name": "set-seccomp-profile",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                ""
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Pod"
                            ]
                        },
                        {
                            "apiGroups": [
                                "apps"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet"
                            ]
                        },
                        {
                            "apiGroups": [
                                "batch"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Job",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "fails if container does not define seccompProfile",
                    "remediation": "Make sure you define seccompProfile at workload or container lever.",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\n# Fails if pod does not define seccompProfile\ndeny[msga] {\n    wl := input[_]\n    wl.kind == \"Pod\"\n    spec := wl.spec\n\tpath_to_search := [\"securityContext\", \"seccompProfile\"]\n\tseccompProfile_not_defined(spec, path_to_search)\n\n\tpath_to_containers := [\"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n    seccompProfile_not_defined(container, path_to_search)\n\n\tfix_path := sprintf(\"%s[%d].%s\", [concat(\".\", path_to_containers), i, concat(\".\", path_to_search)]) \n\tfixPaths := [{\"path\": fix_path, \"value\": \"YOUR_VALUE\"}]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Pod: %v does not define seccompProfile\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n# Fails if workload does not define seccompProfile\ndeny[msga] {\n    wl := input[_]\n\tspec_template_spec_patterns := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tspec_template_spec_patterns[wl.kind]\n    spec := wl.spec.template.spec\n\tpath_to_search := [\"securityContext\", \"seccompProfile\"]\n\tseccompProfile_not_defined(spec, path_to_search)\n\n\tpath_to_containers := [\"spec\", \"template\", \"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n    seccompProfile_not_defined(container, path_to_search)\n\n\tfix_path := sprintf(\"%s[%d].%s\", [concat(\".\", path_to_containers), i, concat(\".\", path_to_search)]) \n\tfixPaths := [{\"path\": fix_path, \"value\": \"YOUR_VALUE\"}]\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Workload: %v does not define seccompProfile\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\n\n# Fails if CronJob does not define seccompProfile\ndeny[msga] {\n\twl := input[_]\n\twl.kind == \"CronJob\"\n    spec := wl.spec.jobTemplate.spec.template.spec\n\tpath_to_search := [\"securityContext\", \"seccompProfile\"]\n\tseccompProfile_not_defined(spec, path_to_search)\n\n\tpath_to_containers := [\"spec\", \"jobTemplate\", \"spec\", \"template\", \"spec\", \"containers\"]\n\tcontainers := object.get(wl, path_to_containers, [])\n\tcontainer := containers[i]\n    seccompProfile_not_defined(container, path_to_search)\n\n\tfix_path := sprintf(\"%s[%d].%s\", [concat(\".\", path_to_containers), i, concat(\".\", path_to_search)]) \n\tfixPaths := [{\"path\": fix_path, \"value\": \"YOUR_VALUE\"}]\n\n\n\tmsga := {\n\t\t\"alertMessage\": sprintf(\"Cronjob: %v does not define seccompProfile\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": fixPaths,\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n\t}\n}\n\nseccompProfile_not_defined(spec, path_to_search){\n\tobject.get(spec, path_to_search, \"\") == \"\"\n}"
                },
                {
                    "name": "set-procmount-default",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                "hostdata.kubescape.cloud"
                            ],
                            "apiVersions": [
                                "v1beta0"
                            ],
                            "resources": [
                                "ControlPlaneInfo"
                            ]
                        },
                        {
                            "apiGroups": [
                                ""
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Pod"
                            ]
                        },
                        {
                            "apiGroups": [
                                "apps"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet"
                            ]
                        },
                        {
                            "apiGroups": [
                                "batch"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Job",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "Fails if container does not define securityContext.procMount to Default.",
                    "remediation": "Set securityContext.procMount to Default",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\n# Fails if container does not define the \"procMount\" parameter as \"Default\"\ndeny[msga] {\n    # checks at first if we the procMountType feature gate is enabled on the api-server\n    obj := input[_]\n    is_control_plane_info(obj)\n    is_proc_mount_type_enabled(obj.data.APIServerInfo.cmdLine)\n\n    # checks if procMount paramenter has the right value in containers\n    pod := input[_]\n    pod.kind = \"Pod\"\n\n\t# retrieve container list\n    container := pod.spec.containers[i]\n    container.securityContext.procMount != \"Default\"\n\n    path := sprintf(\"containers[%d].securityContext.procMount\", [i])\n    msga := {\n\t\t\"alertMessage\": sprintf(\"Pod: %v has containers that do not set 'securityContext.procMount' to 'Default'\", [pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [path],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n    }\n}\n\ndeny[msga] {\n    # checks at first if we the procMountType feature gate is enabled on the api-server\n    obj := input[_]\n    is_control_plane_info(obj)\n    is_proc_mount_type_enabled(obj.data.APIServerInfo.cmdLine)\n\n    # checks if we are managing the right workload kind\n    wl := input[_]\n    manifest_kind := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n    manifest_kind[wl.kind]\n\n    # retrieve container list\n    container := wl.spec.template.spec.containers[i]\n    container.securityContext.procMount != \"Default\"\n\n    path := sprintf(\"containers[%d].securityContext.procMount\", [i])\n    msga := {\n\t\t\"alertMessage\": sprintf(\"Workload: %v has containers that do not set 'securityContext.procMount' to 'Default'\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [path],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n    }\n}\n\ndeny[msga] {\n    # checks at first if we the procMountType feature gate is enabled on the api-server\n    obj := input[_]\n    is_control_plane_info(obj)\n    is_proc_mount_type_enabled(obj.data.APIServerInfo.cmdLine)\n\n    # checks if we are managing the right workload kind\n    cj := input[_]\n    cj.kind = \"CronJob\"\n\n    # retrieve container list\n    container := cj.spec.jobTemplate.spec.template.spec.containers[i]\n    container.securityContext.procMount != \"Default\"\n\n    path := sprintf(\"containers[%d].securityContext.procMount\", [i])\n    msga := {\n\t\t\"alertMessage\": sprintf(\"CronJob: %v has containers that do not set 'securityContext.procMount' to 'Default'\", [cj.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [path],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [cj]\n\t\t}\n    }\n}\n\n\n# check if we are managing ControlPlaneInfo\nis_control_plane_info(obj) {\n\tobj.apiVersion == \"hostdata.kubescape.cloud/v1beta0\"\n\tobj.kind == \"ControlPlaneInfo\"\n}\n\n# check if ProcMountType feature-gate is enabled\nis_proc_mount_type_enabled(command) {\n\tcontains(command, \"--feature-gates=\")\n\targs := regex.split(\" +\", command)\n\tsome i\n\tregex.match(\"ProcMountType=true\", args[i])\n}\n"
                },
                {
                    "name": "set-fsgroup-value",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                ""
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Pod"
                            ]
                        },
                        {
                            "apiGroups": [
                                "apps"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet"
                            ]
                        },
                        {
                            "apiGroups": [
                                "batch"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Job",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "Fails if securityContext.fsGroup is not set.",
                    "remediation": "Set securityContext.fsGroup value",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\nimport future.keywords.if\n\n### POD ###\n\n# Fails if securityContext.fsGroup does not have a values >= 0\ndeny[msga] {\n    # verify the object kind\n    pod := input[_]\n    pod.kind = \"Pod\"\n\n    # check securityContext has fsGroup set properly\n    not fsGroupSetProperly(pod.spec.securityContext)\n\n\n    securityContextPath := \"spec.securityContext\"\n\n    paths := get_paths(pod, securityContextPath)\n    \n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"Pod: %v does not set 'securityContext.fsGroup' with allowed value\", [pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": paths[\"failedPaths\"],\n\t\t\"fixPaths\": paths[\"fixPaths\"],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n    }\n}\n\n\n### CRONJOB ###\n\n# Fails if securityContext.fsGroup does not have a values >= 0\ndeny[msga] {\n    # verify the object kind\n    cj := input[_]\n    cj.kind == \"CronJob\"\n\n    # check securityContext has fsGroup set properly\n    not fsGroupSetProperly(cj.spec.jobTemplate.spec.template.spec.securityContext)\n\n    securityContextPath := \"spec.jobTemplate.spec.template.spec.securityContext\"\n\n    paths := get_paths(cj, securityContextPath)\n    \n    msga := {\n\t\t\"alertMessage\": sprintf(\"CronJob: %v does not set 'securityContext.fsGroup' with allowed value\", [cj.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": paths[\"failedPaths\"],\n\t\t\"fixPaths\": paths[\"fixPaths\"],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [cj]\n\t\t}\n    }\n}\n\n\n### WORKLOAD ###\n\n# Fails if securityContext.fsGroup does not have a values >= 0\ndeny[msga] {\n    # verify the object kind\n    wl := input[_]\n    manifest_kind := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n    manifest_kind[wl.kind]\n\n    # check securityContext has fsGroup set properly\n    not fsGroupSetProperly(wl.spec.template.spec.securityContext)\n\n    path := \"spec.template.spec.securityContext\"\n    paths := get_paths(wl, path)\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"Workload: %v does not set 'securityContext.fsGroup' with allowed value\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": paths[\"failedPaths\"],\n\t\t\"fixPaths\": paths[\"fixPaths\"],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n    }\n}\n\n# fsGroupSetProperly checks if fsGroup has a value >= 0.\nfsGroupSetProperly(securityContext) := true if {\n    securityContext.fsGroup >= 0\n} else := false\n\n\nget_paths(resources, securityContextPath) := result {  \n\n  objectPath := array.concat(split(securityContextPath, \".\"), [\"fsGroup\"])\n  object.get(resources, objectPath, false)\n\n  result = {\"failedPaths\": [], \"fixPaths\": [{\"path\":sprintf(\"%v.fsGroup\", [securityContextPath]), \"value\": \"YOUR_VALUE\"}]}\n} else = result {\n  result = {\"failedPaths\": [securityContextPath], \"fixPaths\": []}\n}\n"
                },
                {
                    "name": "set-fsgroupchangepolicy-value",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                ""
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Pod"
                            ]
                        },
                        {
                            "apiGroups": [
                                "apps"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet"
                            ]
                        },
                        {
                            "apiGroups": [
                                "batch"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Job",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "Fails if securityContext.fsGroup is not set.",
                    "remediation": "Set securityContext.fsGroup value",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\nimport future.keywords.if\n\n### POD ###\n\n# Fails if securityContext.fsGroupChangePolicy does not have an allowed value\ndeny[msga] {\n    # verify the object kind\n    pod := input[_]\n    pod.kind = \"Pod\"\n    \n    # check securityContext has fsGroupChangePolicy set\n    not fsGroupChangePolicySetProperly(pod.spec.securityContext)\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"Pod: %v does not set 'securityContext.fsGroupChangePolicy' with allowed value\", [pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [{\"path\": \"spec.securityContext.fsGroupChangePolicy\", \"value\": \"Always\"}],\n    \"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n    }\n}\n\n### WORKLOAD ###\n\n# Fails if securityContext.fsGroupChangePolicy does not have an allowed value\ndeny[msga] {\n    # verify the object kind\n    wl := input[_]\n    manifest_kind := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n    manifest_kind[wl.kind]\n    \n    # check securityContext has fsGroupChangePolicy set\n    not fsGroupChangePolicySetProperly(wl.spec.template.spec.securityContext)\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"Workload: %v does not set 'securityContext.fsGroupChangePolicy' with allowed value\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [{\"path\": \"spec.template.spec.securityContext.fsGroupChangePolicy\", \"value\": \"Always\"}],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n    }\n}\n\n### CRONJOB ###\n\n# Fails if securityContext.fsGroupChangePolicy does not have an allowed value\ndeny[msga] {\n    # verify the object kind\n    cj := input[_]\n    cj.kind == \"CronJob\"\n\n    # check securityContext has fsGroupChangePolicy set\n    not fsGroupChangePolicySetProperly(cj.spec.jobTemplate.spec.template.spec.securityContext)\n\n    msga := {\n\t\t\"alertMessage\": sprintf(\"CronJob: %v does not set 'securityContext.fsGroupChangePolicy' with allowed value\", [cj.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [{\"path\": \"spec.jobTemplate.spec.template.spec.securityContext.fsGroupChangePolicy\", \"value\": \"Always\"}],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [cj]\n\t\t}\n    }\n}\n\n# fsGroupChangePolicySetProperly checks if applied value is set as appropriate [Always|OnRootMismatch]\nfsGroupChangePolicySetProperly(securityContext) := true if {\n    regex.match(securityContext.fsGroupChangePolicy, \"Always|OnRootMismatch\")\n} else := false\n\n"
                },
                {
                    "name": "set-systctls-params",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                ""
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Pod"
                            ]
                        },
                        {
                            "apiGroups": [
                                "apps"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet"
                            ]
                        },
                        {
                            "apiGroups": [
                                "batch"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Job",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "Fails if securityContext.systctls is not set.",
                    "remediation": "Set securityContext.systctls params",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\n### POD ###\n\n# Fails if securityContext.systctls is not set\ndeny[msga] {\n    # verify the object kind\n\tpod := input[_]\n\tpod.kind = \"Pod\"\n\n\t# check securityContext has systctls set\n    not pod.spec.securityContext.systctls\n\n    path := \"spec.securityContext.systctls\"\n    msga := {\n\t\t\"alertMessage\": sprintf(\"Pod: %v does not set 'securityContext.systctls'\", [pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [{\"path\": path, \"name\": \"net.ipv4.tcp_syncookie\", \"value\": \"1\"}],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n    }\n}\n\n### WORKLOAD ###\n\n# Fails if securityContext.systctls is not set\ndeny[msga] {\n    # verify the object kind\n\twl := input[_]\n\tmanifest_kind := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tmanifest_kind[wl.kind]\n\n\t# check securityContext has systctls set\n    not wl.spec.template.spec.securityContext.systctls\n\n    path := \"spec.template.spec.securityContext.systctls\"\n    msga := {\n\t\t\"alertMessage\": sprintf(\"Workload: %v does not set 'securityContext.systctls'\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [{\"path\": path, \"name\": \"net.ipv4.tcp_syncookie\", \"value\": \"1\"}],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n    }\n}\n\n### CRONJOB ###\n\n# Fails if securityContext.systctls is not set\ndeny[msga] {\n    # verify the object kind\n\tcj := input[_]\n    cj.kind == \"CronJob\"\n\n\t# check securityContext has systctls set\n    not cj.spec.jobTemplate.spec.template.spec.securityContext.systctls\n\n    path := \"spec.jobTemplate.spec.template.spec.securityContext.systctls\"\n    msga := {\n\t\t\"alertMessage\": sprintf(\"CronJob: %v does not set 'securityContext.systctls'\", [cj.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [],\n\t\t\"fixPaths\": [{\"path\": path, \"name\": \"net.ipv4.tcp_syncookie\", \"value\": \"1\"}],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [cj]\n\t\t}\n    }\n}\n"
                },
                {
                    "name": "set-supplementalgroups-values",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                ""
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Pod"
                            ]
                        },
                        {
                            "apiGroups": [
                                "apps"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Deployment",
                                "ReplicaSet",
                                "DaemonSet",
                                "StatefulSet"
                            ]
                        },
                        {
                            "apiGroups": [
                                "batch"
                            ],
                            "apiVersions": [
                                "*"
                            ],
                            "resources": [
                                "Job",
                                "CronJob"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "Fails if securityContext.supplementalgroups is not set.",
                    "remediation": "Set securityContext.supplementalgroups values",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\n### POD ###\n\n# Fails if securityContext.supplementalGroups is not set\ndeny[msga] {\n    # verify the object kind\n\tpod := input[_]\n\tpod.kind = \"Pod\"\n\n\t# check securityContext has supplementalGroups set\n    not pod.spec.securityContext.supplementalGroups\n\n    path := \"spec.securityContext\"\n    msga := {\n\t\t\"alertMessage\": sprintf(\"Pod: %v does not set 'securityContext.supplementalGroups'\", [pod.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [path],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [pod]\n\t\t}\n    }\n}\n\n### WORKLOAD ###\n\n# Fails if securityContext.supplementalGroups is not set\ndeny[msga] {\n    # verify the object kind\n\twl := input[_]\n\tmanifest_kind := {\"Deployment\",\"ReplicaSet\",\"DaemonSet\",\"StatefulSet\",\"Job\"}\n\tmanifest_kind[wl.kind]\n\n\t# check securityContext has supplementalGroups set\n    not wl.spec.template.spec.securityContext.supplementalGroups\n\n    path := \"spec.template.spec.securityContext\"\n    msga := {\n\t\t\"alertMessage\": sprintf(\"Workload: %v does not set 'securityContext.supplementalGroups'\", [wl.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [path],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [wl]\n\t\t}\n    }\n}\n\n### CRONJOB ###\n\n# Fails if securityContext.supplementalGroups is not set\ndeny[msga] {\n    # verify the object kind\n\tcj := input[_]\n    cj.kind == \"CronJob\"\n\n\t# check securityContext has supplementalGroups set\n    not cj.spec.jobTemplate.spec.template.spec.securityContext.supplementalGroups\n\n    path := \"spec.jobTemplate.spec.template.spec.securityContext\"\n    msga := {\n\t\t\"alertMessage\": sprintf(\"CronJob: %v does not set 'securityContext.supplementalGroups'\", [cj.metadata.name]),\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertScore\": 7,\n\t\t\"failedPaths\": [path],\n\t\t\"fixPaths\": [],\n\t\t\"alertObject\": {\n\t\t\t\"k8sApiObjects\": [cj]\n\t\t}\n    }\n}\n"
                }
            ]
        },
        {
            "controlID": "C-0262",
            "name": "Anonymous access enabled",
            "description": "Granting permissions to the system:unauthenticated or system:anonymous user is generally not recommended and can introduce security risks. Allowing unauthenticated access to your Kubernetes cluster can lead to unauthorized access, potential data breaches, and abuse of cluster resources.",
            "remediation": "Review and modify your cluster's RBAC configuration to ensure that only authenticated and authorized users have appropriate permissions based on their roles and responsibilities within your system.",
            "test": "Checks if ClusterRoleBinding/RoleBinding resources give permissions to anonymous user. Also checks in the apiserver if the --anonymous-auth flag is set to false",
            "attributes": {
                "armoBuiltin": true
            },
            "baseScore": 5,
            "scanningScope": {
                "matches": [
                    "cluster",
                    "file"
                ]
            },
            "rules": [
                {
                    "name": "ensure-that-the-api-server-anonymous-auth-argument-is-set-to-false",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                ""
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "Pod"
                            ]
                        }
                    ],
                    "dynamicMatch": [],
                    "ruleDependencies": [],
                    "description": "Disable anonymous requests to the API server.",
                    "remediation": "Edit the API server pod specification file `/etc/kubernetes/manifests/kube-apiserver.yaml` on the Control Plane node and set the below parameter.\n\n \n```\n--anonymous-auth=false\n\n```\n\n#### Impact Statement\nAnonymous requests will be rejected.\n\n#### Default Value\nBy default, anonymous access is enabled.",
                    "ruleQuery": "",
                    "rule": "package armo_builtins\n\nimport future.keywords.in\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tresult = invalid_flag(obj.spec.containers[0].command)\n\tmsg := {\n\t\t\"alertMessage\": \"anonymous requests is enabled\",\n\t\t\"alertScore\": 2,\n\t\t\"failedPaths\": result.failed_paths,\n\t\t\"fixPaths\": result.fix_paths,\n\t\t\"packagename\": \"armo_builtins\",\n\t\t\"alertObject\": {\"k8sApiObjects\": [obj]},\n\t}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) > 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n\n\n# Assume flag set only once\ninvalid_flag(cmd) = result {\n\tcontains(cmd[i], \"--anonymous-auth=true\")\n\tfixed = replace(cmd[i], \"--anonymous-auth=true\", \"--anonymous-auth=false\")\n\tpath := sprintf(\"spec.containers[0].command[%d]\", [i])\n\tresult = {\n\t\t\"failed_paths\": [path],\n\t\t\"fix_paths\": [{\"path\": path, \"value\": fixed}],\n\t}\n}\n\ninvalid_flag(cmd) = result {\n\tfull_cmd = concat(\" \", cmd)\n\tnot contains(full_cmd, \"--anonymous-auth\")\n\tpath := sprintf(\"spec.containers[0].command[%d]\", [count(cmd)])\n\tresult = {\n\t\t\"failed_paths\": [],\n\t\t\"fix_paths\": [{\n\t\t\t\"path\": path,\n\t\t\t\"value\": \"--anonymous-auth=false\",\n\t\t}],\n\t}\n}\n",
                    "resourceEnumerator": "package armo_builtins\n\ndeny[msg] {\n\tobj = input[_]\n\tis_api_server(obj)\n\tmsg := {\"alertObject\": {\"k8sApiObjects\": [obj]}}\n}\n\nis_api_server(obj) {\n\tobj.apiVersion == \"v1\"\n\tobj.kind == \"Pod\"\n\tobj.metadata.namespace == \"kube-system\"\n\tcount(obj.spec.containers) == 1\n\tcount(obj.spec.containers[0].command) > 0\n\tendswith(obj.spec.containers[0].command[0], \"kube-apiserver\")\n}\n"
                },
                {
                    "name": "anonymous-access-enabled",
                    "attributes": {
                        "armoBuiltin": true
                    },
                    "ruleLanguage": "Rego",
                    "match": [
                        {
                            "apiGroups": [
                                "rbac.authorization.k8s.io"
                            ],
                            "apiVersions": [
                                "v1"
                            ],
                            "resources": [
                                "RoleBinding",
                                "ClusterRoleBinding"
                            ]
                        }
                    ],
                    "ruleDependencies": [],
                    "description": "Fails in case anonymous access is enabled on the cluster",
                    "remediation": "Disable anonymous access by passing the --anonymous-auth=false flag to the kube-apiserver component, or if it's a managed cluster, you can remove any RBAC rules which allow anonymous users to perform actions",
                    "ruleQuery": "armo_builtins",
                    "rule": "package armo_builtins\n\n# Fails is rolebinding/clusterrolebinding gives permissions to anonymous user\ndeny[msga] {\n    rolebindings := [rolebinding | rolebinding = input[_]; endswith(rolebinding.kind, \"Binding\")]\n    rolebinding := rolebindings[_]\n\n    isAnonymous(rolebinding)\n\n    msga := {\n        \"alertMessage\": sprintf(\"the following RoleBinding: %v gives permissions to anonymous users\", [rolebinding.metadata.name]),\n        \"alertScore\": 9,\n        \"packagename\": \"armo_builtins\",\n        \"alertObject\": {\n            \"k8sApiObjects\": [rolebinding]\n        }\n    }\n}\n\n\nisAnonymous(binding) {\n    subject := binding.subjects[_]\n    subject.name == \"system:anonymous\"\n}\n\n\nisAnonymous(binding) {\n    subject := binding.subjects[_]\n    subject.name == \"system:unauthenticated\"\n}\n"
                }
            ]
        }
    ],
    "ControlsIDs": [
        "C-0009",
        "C-0017",
        "C-0256",
        "C-0259",
        "C-0258",
        "C-0257",
        "C-0260",
        "C-0261",
        "C-0255",
        "C-0041",
        "C-0044",
        "C-0045",
        "C-0046",
        "C-0048",
        "C-0211",
        "C-0262"
    ]
}